{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cutting-lithuania",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# A robust and versatile computational protocol for fine-mapping and integrative analyses of multiple molecular quantitative trait loci"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-armor",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-promise",
   "metadata": {},
   "source": [
    "(Figure 1 Overview flow chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-granny",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Development of the protocol\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-council",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Comparison with other methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-sandwich",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Applications of the method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-bolivia",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liable-serbia",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Required software dependency\n",
    "The analysis described in this page can be ran on Linux Ubunto. For windows user, the analysis can be ran with `windows subsystem of Linux(wsl)`\n",
    "\n",
    "\n",
    "To run our pipeline, following softwares are needed to be installed in the operating system.\n",
    "1. Python 3\n",
    "2. Singularity\n",
    "3. Script of Script workflow\n",
    "\n",
    "The bioinformatics software that are actually needed to run each of the analysis are packaged in singularity containers and can be downloaded from [synapse](https://www.synapse.org/#!Synapse:syn37177618)\n",
    "\n",
    "-  The `container` parameter for each of the commands in this paper indicates the path to the singularity sif file for the respective step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bored-diameter",
   "metadata": {},
   "source": [
    "### Equipment and hardware\n",
    "It is highly recommended to run our pipeline on a computational cluster with Linux based OS. For personal computer, at least 60GB of memory is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-leave",
   "metadata": {},
   "source": [
    "### Required data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-browse",
   "metadata": {},
   "source": [
    "#### Reference data setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-tulsa",
   "metadata": {},
   "source": [
    "This section described reference data downloading, indexing and preprocessing (if necessary), in preparation for use throughout the pipeline.\n",
    "\n",
    "We have included the PDF document compiled by Data Standardization Working Group in the [on Synapse](https://www.synapse.org/#!Synapse:syn36416587) as well as on [ADSP Dashboard](https://www.niagads.org/adsp/content/adspgcadgenomeresources-v2pdf). It contains the reference data to use for the project.\n",
    "\n",
    "The reference data after we process it (details see Methods section and the rest of the analysis) can be found [in this folder on Synapse](https://www.synapse.org/#!Synapse:syn36416587). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-formation",
   "metadata": {},
   "source": [
    "##### Reference data downloads \n",
    "Following commands download the raw reference data before we processed it. It take around one hour to download all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrong-bidding",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb download_hg_reference --cwd reference_data\n",
    "sos run pipeline/reference_data.ipynb download_gene_annotation --cwd reference_data\n",
    "sos run pipeline/reference_data.ipynb download_ercc_reference --cwd reference_data\n",
    "sos run pipeline/reference_data.ipynb download_dbsnp --cwd reference_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-poster",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Convert transcript feature file gff3 to gtf\n",
    "\n",
    "**Input:** an uncompressed gff3 file.\n",
    "\n",
    "**Output:** a gtf file without HLA, ALT, Decoy but with ERCC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb hg_gtf \\\n",
    "    --cwd reference_data \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.gtf \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy.fasta \\\n",
    "    --container containers/rna_quantification.sif --stranded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepted-spare",
   "metadata": {},
   "source": [
    "##### Collapse transcript features into genes\n",
    "\n",
    "**Input:** a gtf file.\n",
    "\n",
    "**Output:** a gtf file with collapesed gene model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb gene_annotation \\\n",
    "    --cwd reference_data \\\n",
    "    --ercc-gtf reference_data/ERCC92.gtf \\\n",
    "    --hg-gtf reference_data/Homo_sapiens.GRCh38.103.chr.gtf \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy.fasta \\\n",
    "    --container containers/rna_quantification.sif --stranded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "introductory-pledge",
   "metadata": {},
   "source": [
    "##### Process reference fasta file.\n",
    "\n",
    "**Input:** a reference fasta file.\n",
    "\n",
    "**Output:** a reference fasta file without HLA, ALT, Decoy but with ERCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "guilty-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb hg_reference \\\n",
    "    --cwd reference_data \\\n",
    "    --ercc-reference reference_data/ERCC92.fa \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.fa \\\n",
    "    --container container/rna_quantification.sif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "victorian-pasta",
   "metadata": {},
   "source": [
    "##### Generate STAR index based on reference fasta\n",
    "\n",
    "**Input:** a processed reference fasta file.\n",
    "\n",
    "**Output:** A folder of STAR index.\n",
    "\n",
    "This step shall take at least 40G of memory and around 1.5 hour in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focal-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/reference_data.ipynb STAR_index \\\n",
    "    --cwd reference_data \\\n",
    "    --hg-reference reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --mem 40G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weird-airfare",
   "metadata": {},
   "source": [
    "#### Input data setup "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-legislation",
   "metadata": {},
   "source": [
    "The input data used in this protocol can be downloaded from [Synapse](https://www.synapse.org/#!Synapse:syn36416559/files/). The data was originally from the ROSMAP dataset [cite here].We de-identified and keep only a subset of the samples as well as the genomics region to sereve as demostration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-hometown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Procedure 1: Molecular phenotype calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-julian",
   "metadata": {},
   "source": [
    "(Figure 2 molecular phenotype flow chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liked-american",
   "metadata": {},
   "source": [
    "### Bulk RNA-Seq\n",
    "Our protocol can generate two types of molecular phenotypes based on bulk RNA-Seq data. The gene expression and splicing event. After the shared QC and alignment step, the STAR step generate the `Aligned.sortedByCoord.out.md.bam` files that serve as the input of both.\n",
    "\n",
    "#### QC on fasta files\n",
    "\n",
    "Before doing the STAR alignment, the fastqc step can generate a brief description on the quality of the fasta files.\n",
    "\n",
    "**Input:** \n",
    "\n",
    "- `samples`: a collection of fastq file and a `fastqlist` file describing the sample name, file name, and optionally strandness as well as read length of each samples.\n",
    "\n",
    "- `data-dir`: The folder containing the file described in `samples`\n",
    "\n",
    "```\n",
    "ID fq1 fq2 strand read_length\n",
    "sample_1 samp1_r1.fq.gz samp1_r2.fq.gz rf 100\n",
    "sample_2 samp2_r1.fq.gz samp2_r2.fq.gz fr 150\n",
    "sample_3 samp3_r1.fq.gz samp3_r2.fq.gz strand_missing 75\n",
    "```\n",
    "\n",
    "\n",
    "**Output:** a collection of new fastq file without adaptor and a new sample list file corresponding to the newly generated fastq files.\n",
    "\n",
    "**Option**\n",
    "- `cwd` indicates the working diretory of the the command\n",
    "- `STAR-index` `reference-fasta` `ref-flat` `gtf` are reference files prepared in the reference data setup stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/RNA_calling.ipynb fastqc \\\n",
    "    --cwd output/rnaseq/fastqc \\\n",
    "    --samples protocol_data/input_data/RNASeq/fastq/xqtl_protocol_data.fastqlist \\\n",
    "    --data-dir protocol_data/input_data/RNASeq/fastq \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-burden",
   "metadata": {},
   "source": [
    "#### Trim adaptor (Optional)\n",
    "\n",
    "\n",
    "The optionally fastp_trim_adaptor step , leveraging a c++ command line tools `fastp`[cite], can automatically detect and remove the adpators automatically and completely. Alone with the fastq files without adaptors, a new `fastqlist` text file will also be produced to served as the input for STAR_output step, in place the old one. As the fastqs used in this protocol are converted from bam file and already without adaptors. This step can be safely skip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opposed-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/RNA_calling.ipynb fastp_trim_adaptor \\\n",
    "    --cwd output/rnaseq --samples protocol_data/input_data/RNASeq/fastq/xqtl_protocol_data.fastqlist \\\n",
    "    --data-dir protocol_data/input_data/RNASeq/fastq --STAR-index reference_data/STAR_Index/ \\\n",
    "    --gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --reference-fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta \\\n",
    "    --ref-flat reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.ref.flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-identifier",
   "metadata": {},
   "source": [
    "#### Read alignment via STAR\n",
    "\n",
    "The STAR[cite] alignment step produces the input needed for both the eQTL and the splicing QTL, along with multipe QC done through Picard [cite]. If the strand info is missing from the fastqlist for certain samples, the STAR_output step will also automatically detect the strandness of these samples based on `ReadsPerGene.out.tab`. The criteria of determining the strand is based on `how_are_we_stranded_here` [cite]\n",
    "\n",
    "\n",
    "**Input** \n",
    "- `samples`:\n",
    "    - Without adaptor trimming: The fastqlist file described in the **input** section of the `fastp_trim_adaptor` step\n",
    "    - With adaptor trimming: The fastqlist file output from `fastp_trim_adaptor`\n",
    "\n",
    "**Output**\n",
    "- A `Aligned.sortedByCoord.out.md.bam` for each samples, this file serves as the input to the calling of both the gene expression and alternative splicing event.\n",
    "- A `bam_list` file that outline the corresponding bam files for each samples, along with information about strandness.\n",
    "\n",
    "\n",
    "**Option**\n",
    "- The `--uncompressed` option indicates the fastq input is not in gz format, when the fastq input are compressed, removed this option.\n",
    "\n",
    "**Time and Memory**\n",
    "\n",
    "Following step shall take at least 40G of memory around 2 hour in total. \n",
    "\n",
    "**Critical** \n",
    "- It should be noted that, the gtf file used here is `reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf`, the one **before** `Collapse transcript features into genes` ,  i.e. the one without `gene` in its file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/RNA_calling.ipynb STAR_output \\\n",
    "    --cwd output/rnaseq --samples protocol_data/input_data/RNASeq/fastq/xqtl_protocol_data.fastqlist \\\n",
    "    --data-dir protocol_data/input_data/RNASeq/fastq --STAR-index reference_data/STAR_Index/ \\\n",
    "    --gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.gtf \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --reference-fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy_ERCC.fasta \\\n",
    "    --ref-flat reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.ERCC.ref.flat --uncompressed "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-territory",
   "metadata": {},
   "source": [
    "#### Gene expression Calling\n",
    "**Input** \n",
    "- `bam_list`: The output from `STAR_output`\n",
    "\n",
    "**Output**\n",
    "- A `rnaseqc.gene_tpm.gct.gz` and a `rnaseqc.gene_readsCount.gct.gz` that both serve as the input to the RNA-seq QC step.\n",
    "\n",
    "- A `multiqc_report.html` file that describe the overall qualitly metrics for both alignment and expression calling. \n",
    "\n",
    "**Critical** \n",
    "- It should be noted that, the gtf file used here is `reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.gtf`, the one **after** `Collapse transcript features into genes`,  i.e. the one with `gene` in its file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/RNA_calling.ipynb rnaseqc_call \\\n",
    "    --cwd output/rnaseq \\\n",
    "    --samples input_data/RNASeq/fastq/xqtl_protocol_data.fastqlist    --data-dir input_data/RNASeq/fastq \\\n",
    "    --gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.gtf \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --reference-fasta reference_data/GRCh38_full_analysis_set_plus_decoy_hla.noALT_noHLA_noDecoy.fasta \\\n",
    "    --bam_list output/rnaseq/xqtl_protocol_data_bam_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "republican-break",
   "metadata": {},
   "source": [
    "#### Gene expression QC\n",
    "\n",
    "**Input** \n",
    "- `tpm-gct`,`counts-gct`: The output from `rnaseqc_call`\n",
    "\n",
    "**Output**\n",
    "- A `rnaseqc.gene_tpm.gct.gz` and a `rnaseqc.gene_readsCount.gct.gz` that both serve as the input to the RNA-seq QC step.\n",
    "\n",
    "- A `multiqc_report.html` file that describe the overall qualitly metrics for both alignment and expression calling. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-independence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/bulk_expression_QC.ipynb qc \\\n",
    "    --cwd output/rnaseq \\ \\\n",
    "    --tpm-gct output/rnaseq/xqtl_protocol_data.rnaseqc.gene_tpm.gct.gz \\\n",
    "    --counts-gct output/rnaseq/xqtl_protocol_data.rnaseqc.gene_readsCount.gct.gz \\\n",
    "    --container containers/rna_quantification.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "waiting-blank",
   "metadata": {},
   "source": [
    "#### Gene expression Normalization\n",
    "\n",
    "**Input** \n",
    "- `tpm-gct`,`counts-gct`: The output from `qc` of `bulk_expression_QC`\n",
    "\n",
    "**Output**\n",
    "- A `expression.bed.gz` file that are the input files for downstream analysis on eQTL.\n",
    "\n",
    "**Option**\n",
    "- `sample_participant_lookup` a index files that map the sample name in RNA Seq data to that of the genotype data.\n",
    "\n",
    "- `annotation-gtf` the same gtf file used in rnaseqc, i.e. the one after **Collapse transcript features into genes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/bulk_expression_normalization.ipynb normalize \\\n",
    "    --cwd output/rnaseq \\\n",
    "    --tpm-gct output/rnaseq/xqtl_protocol_data.rnaseqc.low_expression_filtered.outlier_removed.tpm.gct.gz \\\n",
    "    --counts-gct output/rnaseq/xqtl_protocol_data.rnaseqc.low_expression_filtered.outlier_removed.geneCount.gct.gz \\\n",
    "    --annotation-gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.ERCC.gtf  \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --count-threshold 1 --sample_participant_lookup reference_data/sample_participant_lookup.rnaseq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "level-soldier",
   "metadata": {},
   "source": [
    "#### Splicing Event Calling\n",
    "In this step the intron usage ratio was quantified via Leafcutter [cite]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-bible",
   "metadata": {},
   "source": [
    "\n",
    "**Input:** \n",
    "- `samples`: the `bam_list` which is the output from `STAR_output` \n",
    "\n",
    "**Output:** \n",
    "- a `intron_usage_perind.counts.gz` file with intron usage ratios that are input to normalization\n",
    "- a `intron_usage_perind_numers.counts.gz` file with actual intron usage count that are input to `annotate_leafcutter_isoforms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-shape",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/splicing_calling.ipynb leafcutter \\\n",
    "    --cwd output/leaf_cutter/ \\\n",
    "    --samples output/rnaseq/xqtl_protocol_data_bam_list \\\n",
    "    --container containers/leafcutter.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rental-bolivia",
   "metadata": {},
   "source": [
    "#### Splicing Event QC and Normalization\n",
    "\n",
    "**Input:** \n",
    "- `ratios`: the `intron_usage_perind.counts.gz` output from `leafcutter` \n",
    "\n",
    "**Output:** \n",
    "- a QCed and normalized phenotype table `gz_raw_data.qqnorm.txt`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/splicing_normalization.ipynb leafcutter_norm \\\n",
    "    --cwd output/leaf_cutter/ \\\n",
    "    --ratios output/leaf_cutter/xqtl_protocol_data_bam_list_intron_usage_perind.counts.gz \\\n",
    "    --container containers/leafcutter.sif "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-fleet",
   "metadata": {},
   "source": [
    "#### Splicing Event Annotation\n",
    "\n",
    "**Input:** \n",
    "- `intron_count`: the `intron_usage_perind_numers.counts.gz` output from `leafcutter` \n",
    "- `phenoFile`: the `gz_raw_data.qqnorm.txt` output from `leafcutter_norm`\n",
    "\n",
    "**Output:** \n",
    "- a `gz_raw_data.qqnorm.formated.bed.gz` file that are the input files for downstream analysis on sQTL.\n",
    "- a `gz_raw_data.qqnorm.phenotype_group.txt` file that needs to be fed into the TensorQTL association scan along with the `bed.gz` files of sQTL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superb-terrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/gene_annotation.ipynb annotate_leafcutter_isoforms \\\n",
    "    --cwd output/leaf_cutter/ \\\n",
    "    --intron_count output/leaf_cutter/xqtl_protocol_data_bam_list_intron_usage_perind_numers.counts.gz \\\n",
    "    --phenoFile output/leaf_cutter/xqtl_protocol_data_bam_list_intron_usage_perind.counts.gz_raw_data.qqnorm.txt \\\n",
    "    --annotation-gtf reference_data/Homo_sapiens.GRCh38.103.chr.reformatted.collapse_only.gene.gtf \\\n",
    "    --container containers/bioinfo.sif \\\n",
    "    --sample_participant_lookup reference_data/sample_participant_lookup.rnaseq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-competition",
   "metadata": {},
   "source": [
    "### Methylation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-level",
   "metadata": {},
   "source": [
    "#### Methylation Calling, QC, and Normalizaion\n",
    "\n",
    "**Input:** \n",
    "- `sample-sheet`: a csv files that are output from illumina, by default in the parenting folders that holds all the idat file for each samples.\n",
    "\n",
    "**Output:** \n",
    "- a `sesame.M.bed.gz`  file that are free of NA and are the input files for downstream analysis on mQTL.\n",
    "\n",
    "**Option:**\n",
    "\n",
    "- `sample_sheet_header_rows` govern the number of header rows in the `sample-sheet`. By default this number is 7 but it can be changed due to different formats\n",
    "\n",
    "**Time and Memory**\n",
    "- `time elapsed`: 1550.12s\n",
    "- `max vms_memory`: 14.62GB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-papua",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/methylation_calling.ipynb sesame \\\n",
    "    --sample-sheet input_data/Methylation/xqtl_protocol_data_arrayMethylation_covariates.tsv  \\\n",
    "    --container containers/methylation.sif --sample_sheet_header_rows 0 --cwd output/methylation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adapted-playback",
   "metadata": {},
   "source": [
    "#### Methylation soft Imputation and NA removal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "classified-qualification",
   "metadata": {},
   "source": [
    "Many of the methylation matrix are filled with NA. All the probes with more than 10% missing rate are removed by default. Soft-Imputation are applied to the result. to filled in the remaining NA cells.\n",
    "\n",
    "\n",
    "**Input:** \n",
    "- `phenoFile`: the `sesame.M.bed.gz` output from `sesame`\n",
    "\n",
    "**Output:** \n",
    "- a `sesame.M.bed.gz`  file that are free of NA and are the input files for downstream analysis on mQTL.\n",
    "\n",
    "**Time and Memory**\n",
    "- `time elapsed`: 143.58s\n",
    "- `max vms_memory`: 8.1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-hearts",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb bed_filter_na \\\n",
    "        --phenoFile output/methylation/xqtl_protocol_data_arrayMethylation_covariates.sesame.M.bed.gz \\\n",
    "        --cwd ./output/methylation/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-passage",
   "metadata": {},
   "source": [
    "## Procedure 2: Data Processing and QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-entity",
   "metadata": {},
   "source": [
    "### Phenotype processing\n",
    "The molecular phenotype files will each be partioned into 1 bed.gz per chromosome. Doing so allows `cis-eQTL association testing` be done in parallel. \n",
    "\n",
    "\n",
    "**Input:** \n",
    "- `phenoFile`: \n",
    "    - eQTL: the `expression.bed.gz` output from `normalization` step of gene expression calling.\n",
    "    - sQTL: the `gz_raw_data.qqnorm.formated.bed.gz` from `annotate_leafcutter_isoforms`.\n",
    "    - mQTL: the `sesame.M.bed.gz` output from `bed_filter_na` of methylation calling.\n",
    "\n",
    "**Output:** \n",
    "- a collection of `bed.gz` files that are listed in a `bed.per_chrom.recipe` file for each molecular phenotypes.\n",
    "\n",
    "**Time and Memory**\n",
    "- `time elapsed`: 8.60s\n",
    "- `max vms_memory`: 15.36GB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd output/data_preprocessing/protocol-eqtl/phenotype_data  \\\n",
    "    --phenoFile output/rnaseq/xqtl_protocol_data.rnaseqc.low_expression_filtered.outlier_removed.tmm.expression.bed.gz \\\n",
    "    --region-list  <(zcat output/rnaseq/xqtl_protocol_data.rnaseqc.low_expression_filtered.outlier_removed.tmm.expression.bed.gz  | cut -f 1,2,3,4)  \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --mem 16G       \n",
    "\n",
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd output/data_preprocessing/protocol-sqtl/phenotype_data  \\\n",
    "    --phenoFile output/leaf_cutter/xqtl_protocol_data_bam_list_intron_usage_perind.counts.gz_raw_data.qqnorm.formated.bed.gz \\\n",
    "    --region-list  <(zcat output/leaf_cutter/xqtl_protocol_data_bam_list_intron_usage_perind.counts.gz_raw_data.qqnorm.formated.bed.gz  | cut -f 1,2,3,4)  \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --mem 16G       \n",
    "\n",
    "sos run pipeline/phenotype_formatting.ipynb partition_by_chrom \\\n",
    "    --cwd output/data_preprocessing/protocol-mqtl/phenotype_data  \\\n",
    "    --phenoFile output/methylation/xqtl_protocol_data_arrayMethylation_covariates.sesame.beta.filter_na.soft.bed.gz \\\n",
    "    --region-list  <(zcat output/methylation/xqtl_protocol_data_arrayMethylation_covariates.sesame.beta.filter_na.soft.bed.gz  | cut -f 1,2,3,4)  \\\n",
    "    --container containers/rna_quantification.sif \\\n",
    "    --mem 16G       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mobile-wagner",
   "metadata": {},
   "source": [
    "### Genotype QC and PCA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-marsh",
   "metadata": {},
   "source": [
    "### Factor analysis for phenotype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-proof",
   "metadata": {},
   "source": [
    "## Procedure 3: Univariate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "declared-premises",
   "metadata": {},
   "source": [
    "### Cis Association Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tight-timothy",
   "metadata": {},
   "source": [
    "### Trans Association Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-vancouver",
   "metadata": {},
   "source": [
    "### Univariate Finemapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "described-advocacy",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Procedure 4: Multi-variate analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attractive-produce",
   "metadata": {},
   "source": [
    "### Multivariate Adaptive Shinkage (MASH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-parish",
   "metadata": {},
   "source": [
    "### Multivariate-Finemapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-beaver",
   "metadata": {},
   "source": [
    "## Anticipated results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-remove",
   "metadata": {},
   "source": [
    "### Association Scan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-joint",
   "metadata": {},
   "source": [
    "### MASH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-verse",
   "metadata": {},
   "source": [
    "### Fine mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.22.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
