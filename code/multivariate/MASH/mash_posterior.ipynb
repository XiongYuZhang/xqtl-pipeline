{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# MASH analysis pipeline with posterior computation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Compute MASH posteriors\n",
    "\n",
    "In the GTEx V6 paper we assumed one eQTL per gene and applied the model learned above to those SNPs. Under that assumption, the input data for posterior calculation will be the `dat$strong.*` matrices.\n",
    "It is a fairly straightforward procedure as shown in [this vignette](https://stephenslab.github.io/mashr/articles/eQTL_outline.html).\n",
    "\n",
    "But it is often more interesting to apply MASH to given list of eQTLs, eg, from those from fine-mapping results. In GTEx V8 analysis we obtain such gene-SNP pairs from DAP-G fine-mapping analysis. See [this notebook](https://stephenslab.github.io/gtex-eqtls/analysis/Independent_eQTL_Results.html) for how the input data is prepared. The workflow below takes a number of input chunks (each chunk is a list of matrices `dat$Bhat` and `dat$Shat`) \n",
    "and computes posterior for each chunk. It is therefore suited for running in parallel posterior computation for all gene-SNP pairs, if input data chunks are provided.\n",
    "\n",
    "\n",
    "```\n",
    "JOB_OPT=\"-c midway2.yml -q midway2\"\n",
    "DATA_DIR=/project/compbio/GTEx_eQTL/independent_eQTL\n",
    "sos run workflows/mashr_flashr_workflow.ipynb posterior \\\n",
    "    $JOB_OPT \\\n",
    "    --posterior-input $DATA_DIR/DAPG_pip_gt_0.01-AllTissues/DAPG_pip_gt_0.01-AllTissues.*.rds \\\n",
    "                      $DATA_DIR/ConditionalAnalysis_AllTissues/ConditionalAnalysis_AllTissues.*.rds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Apply posterior calculations\n",
    "#[posterior_1]\n",
    "parameter: analysis_units = path\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: mash_model = path(f\"{cwd:a}/RDS/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "parameter: posterior_input = [path(x[0]) for x in regions]\n",
    "parameter: posterior_vhat_files = paths()\n",
    "# eg, if data is saved in R list as data$strong, then\n",
    "# when you specify `--data-table-name strong` it will read the data as\n",
    "# readRDS('{_input:r}')$strong\n",
    "parameter: data_table_name = ''\n",
    "parameter: bhat_table_name = 'bhat'\n",
    "parameter: shat_table_name = 'sbhat'\n",
    "mash_model = f\"{mash_model:a}\"\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "\n",
    "skip_if(len(posterior_input) == 0, msg = \"No posterior input data to compute on. Please specify it using --posterior-input.\")\n",
    "fail_if(len(posterior_vhat_files) > 1 and len(posterior_vhat_files) != len(posterior_input), msg = \"length of --posterior-input and --posterior-vhat-files do not agree.\")\n",
    "for p in posterior_input:\n",
    "    fail_if(not p.is_file(), msg = f'Cannot find posterior input file ``{p}``')\n",
    "\n",
    "depends: mash_model\n",
    "input: posterior_input, group_by = 1\n",
    "output: f\"{cwd}/{_input:bn}.posterior.rds\"\n",
    "task: trunk_workers = 1, walltime = '20h', trunk_size = 1, mem = '20G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    library(mashr)\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    data = readRDS(\"${_input}\")${('$' + data_table_name) if data_table_name else ''}\n",
    "    if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "      message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "      data$bhat = data$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$sbhat = data$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$Z = data$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "    }\n",
    "    data <- handle_nan_etc(data)\n",
    "    vhat = readRDS(\"${vhat_data if len(posterior_vhat_files) == 0 else posterior_vhat_files[_index]}\")\n",
    "    mash_data = mash_set_data(data$${bhat_table_name}, Shat=data$${shat_table_name}, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "    mash_output = mash_compute_posterior_matrices(readRDS(\"${mash_model}\"), mash_data,output_posterior_cov=TRUE)\n",
    "    mash_output$snps = data$snps\n",
    "    saveRDS(mash_output, ${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[posterior_2]\n",
    "input: group_by = \"all\"\n",
    "output:f\"{cwd}/mash_output_list\"\n",
    "python: expand = \"$[ ]\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    library(mashr)\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"#mash_result\" :  [$[_input:ar,]] }).to_csv(\"$[_output]\",index = False ,header = False, sep = \"t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Apply posterior calculations, output_posterior_cov = T\n",
    "[posterior_1]\n",
    "parameter: analysis_units = path\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: mash_model = path(f\"{cwd:a}/RDS/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "parameter: posterior_input = [path(x[0]) for x in regions]\n",
    "parameter: posterior_vhat_files = paths()\n",
    "# eg, if data is saved in R list as data$strong, then\n",
    "# when you specify `--data-table-name strong` it will read the data as\n",
    "# readRDS('{_input:r}')$strong\n",
    "parameter: per_chunk = '100'\n",
    "parameter: data_table_name = ''\n",
    "parameter: bhat_table_name = 'bhat'\n",
    "parameter: shat_table_name = 'sbhat'\n",
    "mash_model = f\"{mash_model:a}\"\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "\n",
    "skip_if(len(posterior_input) == 0, msg = \"No posterior input data to compute on. Please specify it using --posterior-input.\")\n",
    "fail_if(len(posterior_vhat_files) > 1 and len(posterior_vhat_files) != len(posterior_input), msg = \"length of --posterior-input and --posterior-vhat-files do not agree.\")\n",
    "for p in posterior_input:\n",
    "    fail_if(not p.is_file(), msg = f'Cannot find posterior input file ``{p}``')\n",
    "\n",
    "depends: mash_model\n",
    "input: posterior_input, group_by = per_chunk\n",
    "output: f\"{cwd}/cache/mash_output_list_{output_suffix}.{_index+1}\"\n",
    "task: trunk_workers = 1, walltime = '20h', trunk_size = 1, mem = '20G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\", container = container\n",
    "    library(mashr)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    outlist = data.frame()\n",
    "    for (f in c(${_input:r,})) try({\n",
    "     data = readRDS(f)${('$' + data_table_name) if data_table_name else ''}\n",
    "    if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "      message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "      data$bhat = data$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$sbhat = data$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$Z = data$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "    }\n",
    "    data <- handle_nan_etc(data)\n",
    "    vhat = readRDS(\"${vhat_data if len(posterior_vhat_files) == 0 else posterior_vhat_files[_index]}\")\n",
    "    mash_data = mash_set_data(data$${bhat_table_name}, Shat=data$${shat_table_name}, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "    mash_output = mash_compute_posterior_matrices(readRDS(\"${mash_model}\"), mash_data,output_posterior_cov=TRUE)\n",
    "    mash_output$snps = data$snps\n",
    "    #saveRDS(mash_output, ${_output:r})\n",
    "    samplename<-str_split(f,\"/\",simplify = T)%>%.[length(.)]%>%gsub('.rds','',.)\n",
    "    saveRDS(mash_output, paste0(\"${_output:d}\",\"/\",samplename,\".posterior.rds\"))\n",
    "    outlist<-rbind(outlist,paste0(\"${_output:d}\",\"/\",samplename,\".posterior.rds\"))\n",
    "    })\n",
    "    write.table(outlist,${_output:r},col.names=F, row.names=F, quote=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[posterior_2]\n",
    "\n",
    "input: group_by = \"all\"\n",
    "output:f\"{cwd}/mash_output_list_{output_suffix}\"\n",
    "bash: expand ='${ }', workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "     cd ${_input[0]:d}\n",
    "     cat mash_output_list_*[0-9] >> posterior_file_list\n",
    "     awk -F 'cis_long_table.' '{print $2}' posterior_file_list| awk -F '.posterior.rds' '{print $1}'|paste - posterior_file_list > ${_output:r}\n",
    "     rm posterior_file_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### Posterior results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "1. The outcome of the `[posterior]` step should produce a number of serialized R objects `*.batch_*.posterior.rds` (can be loaded to R via `readRDS()`) -- I chopped data to batches to take advantage of computing in multiple cluster nodes. It should be self-explanary but please let me know otherwise.\n",
    "2. Other posterior related files are:\n",
    "    1. `*.batch_*.yaml`: gene-SNP pairs of interest, identified elsewhere (eg. fine-mapping analysis). \n",
    "    2. The corresponding univariate analysis summary statistics for gene-SNPs from `*.batch_*.yaml` are extracted and saved to `*.batch_*.rds`, creating input to the `[posterior]` step.\n",
    "    3. Note the `*.batch_*.stdout` file documents some SNPs found in fine-mapping results but not found in the original `fastqtl` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Slice Posterior \n",
    "\n",
    "take all the 13K genes, and for those with missing conditions we just drop those corresponding rows and cols in the prior model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Apply posterior calculations\n",
    "#[sliceposterior_1]\n",
    "parameter: analysis_units = path\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: mash_model = path(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "parameter: posterior_input = [path(x[0]) for x in regions]\n",
    "parameter: posterior_vhat_files = paths()\n",
    "# eg, if data is saved in R list as data$strong, then\n",
    "# when you specify `--data-table-name strong` it will read the data as\n",
    "# readRDS('{_input:r}')$strong\n",
    "parameter: data_table_name = ''\n",
    "parameter: bhat_table_name = 'bhat'\n",
    "parameter: shat_table_name = 'sbhat'\n",
    "parameter: per_chunk = '1000'\n",
    "mash_model = f\"{mash_model:a}\"\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "\n",
    "skip_if(len(posterior_input) == 0, msg = \"No posterior input data to compute on. Please specify it using --posterior-input.\")\n",
    "fail_if(len(posterior_vhat_files) > 1 and len(posterior_vhat_files) != len(posterior_input), msg = \"length of --posterior-input and --posterior-vhat-files do not agree.\")\n",
    "for p in posterior_input:\n",
    "    fail_if(not p.is_file(), msg = f'Cannot find posterior input file ``{p}``')\n",
    "\n",
    "depends: mash_model\n",
    "input: posterior_input, group_by = per_chunk\n",
    "output: f\"{cwd}/cache/mash_output_list_{_index+1}\"\n",
    "task: trunk_workers = 1, walltime = '20h', trunk_size = 1, mem = '20G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    library(mashr)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    outlist = data.frame()\n",
    "    for (f in c(${_input:r,})) try({\n",
    "    data = readRDS(f)${('$' + data_table_name) if data_table_name else ''}\n",
    "    #data = readRDS(\"${_input}\")${('$' + data_table_name) if data_table_name else ''}\n",
    "\n",
    "    if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "      message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "      data$bhat = data$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$sbhat = data$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$Z = data$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "    }\n",
    "    \n",
    "    all.samples<-colnames(data$bhat)\n",
    "    all.snps<-rownames(data$bhat)\n",
    "    \n",
    "    vhat = readRDS(\"${vhat_data if len(posterior_vhat_files) == 0 else posterior_vhat_files[_index]}\")\n",
    "    mash_model <- readRDS(\"${mash_model}\")\n",
    "    \n",
    "    #remove the rows and cols containing NA\n",
    "    na.test<-data$bhat %>% as.data.frame()%>% select_if(~any(!is.na(.)))%>% na.omit%>%as.matrix\n",
    "    #recording meaningful rows and cols\n",
    "    samples<-colnames(na.test)\n",
    "    snps<-rownames(na.test)\n",
    "    \n",
    "    if(length(all.snps)!=length(snps) | length(all.samples)!=length(samples)){\n",
    "        #slice the data\n",
    "        data$bhat<-data$bhat[snps,samples]%>%as.matrix\n",
    "        colnames(data$bhat)<-samples\n",
    "        data$sbhat<-data$sbhat[snps,samples]%>%as.matrix\n",
    "        colnames(data$sbhat)<-samples\n",
    "        data$Z<-data$Z[snps,samples]%>%as.matrix\n",
    "        colnames(data$Z)<-samples\n",
    "        data$snp<-data$snp[data$snp%in%snps]\n",
    "        vhat<-vhat[samples,samples]%>%as.matrix\n",
    "        colnames(vhat)<-samples\n",
    "  \n",
    "        if(length(all.samples)!=length(samples)){\n",
    "            ##slice the prior\n",
    "            cov<-mash_model$fitted_g$Ulist\n",
    "            for (d in names(cov)) {\n",
    "                if(d %in% setdiff(all.samples,samples)){\n",
    "                    cov[[d]]<-NULL\n",
    "                }\n",
    "                if(d %in% paste0(\"ED_\",setdiff(all.samples,samples))){\n",
    "                    cov[[d]]<-NULL\n",
    "                }\n",
    "                if(d %in% samples){\n",
    "                    cov[[d]]<-matrix(0,length(samples),length(samples))\n",
    "                    cov[[d]][which(samples==d),which(samples==d)]<-1\n",
    "                }else if(d == \"identity\"){\n",
    "                    cov[[d]]<-matrix(0,length(samples),length(samples))\n",
    "                    cov[[d]][1,1]<-1  \n",
    "                }else if(is.null(colnames(cov[[d]]))){\n",
    "                    cov[[d]] <- cov[[d]][1:length(samples),1:length(samples)]\n",
    "                } else {\n",
    "                    cov[[d]] <- cov[[d]][samples,samples]\n",
    "                }\n",
    "                    }\n",
    "                for (d in names(cov)) {\n",
    "                    cov[[d]] <- cov[[d]]%>%as.matrix\n",
    "                }\n",
    "                #slide the prior and related file\n",
    "                mash_model$fitted_g$Ulist<-cov\n",
    "                diff.sam<-setdiff(all.samples,samples)\n",
    "                for(s in diff.sam){mash_model$fitted_g$pi<-mash_model$fitted_g$pi[-grep(s,names(mash_model$fitted_g$pi))]}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "  \n",
    "  \n",
    "    \n",
    "    mash_data = mash_set_data(data$${bhat_table_name}, Shat=data$${shat_table_name}, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "    mash_output = mash_compute_posterior_matrices(mash_model, mash_data)\n",
    "    mash_output$snps = data$snps\n",
    "    #saveRDS(mash_output, ${_output:r})\n",
    "    samplename<-str_split(f,\"/\",simplify = T)%>%.[length(.)]%>%gsub('.rds','',.)\n",
    "    saveRDS(mash_output, paste0(\"${_output:d}\",\"/\",samplename,\".posterior.rds\"))\n",
    "    outlist<-rbind(outlist,paste0(\"${_output:d}\",\"/\",samplename,\".posterior.rds\"))\n",
    "    })\n",
    "    write.table(outlist,${_output:r},col.names=F, row.names=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "# Apply posterior calculations with slice NA and set NaN/Inf 0/1E3, output_posterior_cov = T \n",
    "[sliceposterior_1]\n",
    "parameter: analysis_units = path\n",
    "regions = [x.replace(\"\\\"\",\"\").strip().split() for x in open(analysis_units).readlines() if x.strip() and not x.strip().startswith('#')]\n",
    "parameter: mash_model = path(f\"{cwd:a}/{output_prefix}.{effect_model}.V_{vhat}.mash_model.rds\")\n",
    "parameter: posterior_input = [path(x[0]) for x in regions]\n",
    "parameter: posterior_vhat_files = paths()\n",
    "# eg, if data is saved in R list as data$strong, then\n",
    "# when you specify `--data-table-name strong` it will read the data as\n",
    "# readRDS('{_input:r}')$strong\n",
    "parameter: data_table_name = ''\n",
    "parameter: bhat_table_name = 'bhat'\n",
    "parameter: shat_table_name = 'sbhat'\n",
    "parameter: per_chunk = '100'\n",
    "mash_model = f\"{mash_model:a}\"\n",
    "##  conditions can be excluded if needs arise. If nothing to exclude keep the default 0\n",
    "parameter: exclude_condition = [\"1\",\"3\"]\n",
    "parameter: output_suffix = \"all\"\n",
    "\n",
    "skip_if(len(posterior_input) == 0, msg = \"No posterior input data to compute on. Please specify it using --posterior-input.\")\n",
    "fail_if(len(posterior_vhat_files) > 1 and len(posterior_vhat_files) != len(posterior_input), msg = \"length of --posterior-input and --posterior-vhat-files do not agree.\")\n",
    "for p in posterior_input:\n",
    "    fail_if(not p.is_file(), msg = f'Cannot find posterior input file ``{p}``')\n",
    "\n",
    "depends: mash_model\n",
    "input: posterior_input, group_by = per_chunk\n",
    "output: f\"{cwd}/cache/mash_output_list_{_index+1}\"\n",
    "task: trunk_workers = 1, walltime = '20h', trunk_size = 1, mem = '20G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    library(mashr)\n",
    "    library(dplyr)\n",
    "    library(stringr)\n",
    "    handle_nan_etc = function(x) {\n",
    "      x$bhat[which(is.nan(x$bhat))] = 0\n",
    "      x$sbhat[which(is.nan(x$sbhat) | is.infinite(x$sbhat))] = 1E3\n",
    "      return(x)\n",
    "    }\n",
    "    \n",
    "    outlist = data.frame()\n",
    "    for (f in c(${_input:r,})) try({\n",
    "    data = readRDS(f)${('$' + data_table_name) if data_table_name else ''}\n",
    "    data <- handle_nan_etc(data)\n",
    "      \n",
    "    if(c(${\",\".join(exclude_condition)})[1] > 0 ){\n",
    "      message(paste(\"Excluding condition ${exclude_condition} from the analysis\"))\n",
    "      data$bhat = data$bhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$sbhat = data$sbhat[,-c(${\",\".join(exclude_condition)})]\n",
    "      data$Z = data$Z[,-c(${\",\".join(exclude_condition)})]\n",
    "    }\n",
    "    \n",
    "    all.samples<-colnames(data$bhat)\n",
    "    all.snps<-rownames(data$bhat)\n",
    "    \n",
    "    vhat = readRDS(\"${vhat_data if len(posterior_vhat_files) == 0 else posterior_vhat_files[_index]}\")\n",
    "    mash_model <- readRDS(\"${mash_model}\")\n",
    "    \n",
    "    #remove the rows and cols containing NA\n",
    "    na.test<-data$bhat %>% as.data.frame()%>% select_if(~any(!is.na(.)))%>% na.omit%>%as.matrix\n",
    "    #recording meaningful rows and cols\n",
    "    samples<-colnames(na.test)\n",
    "    snps<-rownames(na.test)\n",
    "    \n",
    "    if(length(all.snps)!=length(snps) | length(all.samples)!=length(samples)){\n",
    "        #slice the data\n",
    "        data$bhat<-data$bhat[snps,samples]%>%as.matrix\n",
    "        colnames(data$bhat)<-samples\n",
    "        data$sbhat<-data$sbhat[snps,samples]%>%as.matrix\n",
    "        colnames(data$sbhat)<-samples\n",
    "        data$Z<-data$Z[snps,samples]%>%as.matrix\n",
    "        colnames(data$Z)<-samples\n",
    "        data$snp<-data$snp[data$snp%in%snps]\n",
    "        vhat<-vhat[samples,samples]%>%as.matrix\n",
    "        colnames(vhat)<-samples\n",
    "  \n",
    "        if(length(all.samples)!=length(samples)){\n",
    "            ##slice the prior\n",
    "            cov<-mash_model$fitted_g$Ulist\n",
    "            for (d in names(cov)) {\n",
    "                if(d %in% setdiff(all.samples,samples)){\n",
    "                    cov[[d]]<-NULL\n",
    "                }\n",
    "                if(d %in% paste0(\"ED_\",setdiff(all.samples,samples))){\n",
    "                    cov[[d]]<-NULL\n",
    "                }\n",
    "                if(d %in% samples){\n",
    "                    cov[[d]]<-matrix(0,length(samples),length(samples))\n",
    "                    cov[[d]][which(samples==d),which(samples==d)]<-1\n",
    "                }else if(d == \"identity\"){\n",
    "                    cov[[d]]<-matrix(0,length(samples),length(samples))\n",
    "                    cov[[d]][1,1]<-1  \n",
    "                }else if(is.null(colnames(cov[[d]]))){\n",
    "                    cov[[d]] <- cov[[d]][1:length(samples),1:length(samples)]\n",
    "                } else {\n",
    "                    cov[[d]] <- cov[[d]][samples,samples]\n",
    "                }\n",
    "                    }\n",
    "                for (d in names(cov)) {\n",
    "                    cov[[d]] <- cov[[d]]%>%as.matrix\n",
    "                }\n",
    "                #slide the prior and related file\n",
    "                mash_model$fitted_g$Ulist<-cov\n",
    "                diff.sam<-setdiff(all.samples,samples)\n",
    "                for(s in diff.sam){mash_model$fitted_g$pi<-mash_model$fitted_g$pi[-grep(s,names(mash_model$fitted_g$pi))]}\n",
    "            }\n",
    "        }\n",
    "    \n",
    "  \n",
    "  \n",
    "    \n",
    "    mash_data = mash_set_data(data$${bhat_table_name}, Shat=data$${shat_table_name}, alpha=${1 if effect_model == 'EZ' else 0}, V=vhat, zero_Bhat_Shat_reset = 1E3)\n",
    "    mash_output = mash_compute_posterior_matrices(mash_model, mash_data,output_posterior_cov=TRUE)\n",
    "    mash_output$snps = data$snps\n",
    "    #saveRDS(mash_output, ${_output:r})\n",
    "    samplename<-str_split(f,\"/\",simplify = T)%>%.[length(.)]%>%gsub('.rds','',.)\n",
    "    saveRDS(mash_output, paste0(\"${_output:d}\",\"/\",samplename,\".posterior.rds\"))\n",
    "    outlist<-rbind(outlist,paste0(\"${_output:d}\",\"/\",samplename,\".posterior.rds\"))\n",
    "    })\n",
    "    write.table(outlist,${_output:r},col.names=F, row.names=F, quote=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[sliceposterior_2]\n",
    "input: group_by = \"all\"\n",
    "output:f\"{cwd}/mash_output_list_{output_suffix}\"\n",
    "bash: expand ='${ }', workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "     cd ${_input[0]:d}\n",
    "     cat mash_output_list_*[0-9] >> posterior_file_list\n",
    "     awk -F 'cis_long_table.' '{print $2}' posterior_file_list| awk -F '.posterior.rds' '{print $1}'|paste - posterior_file_list > ${_output:r}\n",
    "     rm posterior_file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[sliceposterior_2]\n",
    "\n",
    "input: group_by = 1\n",
    "output:f\"{cwd}/cache/{cwd:b}_{_index+1}.posterior.rds\"\n",
    "R: expand ='${ }', workdir = cwd, stderr = f\"{_output:n}.stderr\", stdout = f\"{_output:n}.stdout\"\n",
    "    library(tidyverse)     \n",
    "    ps<-list(pm=NULL,lfsr=NULL)\n",
    "    samples<-read.table(c(${_input:r,}))$V1\n",
    "\n",
    "    for (f in samples) {\n",
    "    tmp<-readRDS(f)\n",
    "    #get gene name\n",
    "    #g<-f%>%gsub(\".posterior.rds\",\"\",.)%>%stringr::str_split(.,\"[.]\",simplify=T)\n",
    "    #gene<-ifelse(g[length(g)]%>%grep(\"\\\\d\",.)==g[length(g)], paste0(paste(g[length(g)-1],g[length(g)],sep=\".\")),g[length(g)])\n",
    "    gene<-stringr::str_split(string = f, pattern = \"norminal.cis_long_table.\",simplify = T)[[2]]%>%\n",
    "               gsub(\".posterior.rds\",\"\",.)\n",
    "    #get the matrix of pm and lfsr\n",
    "    tmp.pm<-tmp$PosteriorMean%>%as.data.frame()\n",
    "    tmp.lf<-tmp$lfsr%>%as.data.frame()\n",
    "    \n",
    "    #change the rownames\n",
    "    names <- c( rownames(ps$pm) , paste(gene,str_split(rownames(tmp.pm),\":\",simplify=T)[,2],sep=\"_\") )\n",
    "    ps$pm<-plyr::rbind.fill(ps$pm, tmp.pm)\n",
    "    rownames(ps$pm) <- make.names(names,unique=T)\n",
    "    \n",
    "    namess <- c( rownames(ps$lfsr) , paste(gene,str_split(rownames(tmp.lf),\":\",simplify=T)[,2],sep=\"_\") )\n",
    "    ps$lfsr<-plyr::rbind.fill(ps$lfsr, tmp.lf)\n",
    "    rownames(ps$lfsr) <- make.names(namess,unique=T)\n",
    "    }\n",
    "    \n",
    "    saveRDS(ps,${_output:r})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "#[sliceposterior_3]\n",
    "input: group_by = \"all\"\n",
    "output: f\"{cwd}/{cwd:b}.posterior.rds\"\n",
    "task: trunk_workers = 1, walltime = '1h', trunk_size = 1, mem = '100G', cores = 1, tags = f'{_output:bn}'\n",
    "R: expand = \"${ }\", container = container,stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', volumes = [f'{cwd:ad}:{cwd:ad}']\n",
    "    merge_data = function(res, one_data) {\n",
    "      if (length(res) == 0) {\n",
    "          return(one_data)\n",
    "      } else {\n",
    "          for (d in names(one_data)) {\n",
    "            res[[d]] = rbind(res[[d]], one_data[[d]])\n",
    "          }\n",
    "          return(res)\n",
    "      }\n",
    "    }\n",
    "    dat = list()\n",
    "    for (f in c(${_input:r,})) {\n",
    "      dat = merge_data(dat, readRDS(f))\n",
    "    }\n",
    "    \n",
    "    saveRDS(dat, ${_output:r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "panel": {
    "displayed": true,
    "height": 0,
    "style": "side"
   },
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
