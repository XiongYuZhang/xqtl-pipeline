{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "authorized-highland",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "# Phenotype data imputation\n",
    "\n",
    "This workflow contains a collection of methods on imputation of missing omics data values.\n",
    "\n",
    "\n",
    "## Input\n",
    "* A molecular phenotype data with missing where first four columns are chr, start, end, and ID. The rest columns are samples.\n",
    "\n",
    "## Output\n",
    "* A complete molecular phenotype data where first four columns are chr, start, end, and ID. The rest columns are samples.\n",
    "\n",
    "## MWE\n",
    "FIXME: will update this after container is done. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-locking",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "sos run phenotype_imputation.ipynb flash \\\n",
    "    --phenoFile ./proteomics/rosmap/test1.bed.gz \\\n",
    "    --cwd ./proteomics/rosmap/ \\\n",
    "    --mem 40G \\\n",
    "    --walltime 100h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nuclear-tumor",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Work directory & output directory\n",
    "parameter: cwd = path(\"output\")\n",
    "# Molecular phenotype matrix\n",
    "parameter: phenoFile = path\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"72h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 20\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complex-kitty",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[flash]\n",
    "# prior distribution of loadings and factors\n",
    "parameter: prior = ebnm_point_normal\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(flashier)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    f <- flashier::flash(as.matrix(pheno_NAs), ebnm_fn = prior)\n",
    "    Yfill <- ifelse(is.na(as.matrix(pheno_NAs)), fitted(f), as.matrix(pheno_NAs))\n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "wireless-draft",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[missforest]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(flashier)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- missForest(as.matrix(pheno_NAs), parallelize = 'variables')$ximp\n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-hypothetical",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[missxgboost]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   source('/mnt/vast/hpc/csg/zq2209/xgb_imp.R')\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- xgboost_imputation(as.matrix(pheno_NAs))\n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exclusive-complaint",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[knn]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(impute)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- impute.knn(as.matrix(pheno_NAs), rowmax = 1)$data\n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entire-legislation",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[soft]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(softImpute)\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    X_mis_C <- as(as.matrix(pheno_NAs), \"Incomplete\")\n",
    "    ###uses \"svd\" algorithm\n",
    "    fit <- softImpute(X_mis_C,rank = 50,lambda = 30,type = \"svd\")\n",
    "    Yfill <- complete(as.matrix(pheno_NAs),fit)\n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-smoke",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mean]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- as.matrix(pheno_NAs)\n",
    "    for (t.row in 1:nrow(pheno_NAs)) {\n",
    "        Yfill[t.row, is.na(Yfill[t.row,])] <- rowMeans(Yfill, na.rm = TRUE)[t.row] \n",
    "    }    \n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-kidney",
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[lod]\n",
    "input: phenoFile\n",
    "output: f'{cwd:a}/{_input:bn}.imputed.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime,  mem = mem, tags = f'{step_name}_{_output:bn}'  \n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(\"dplyr\")\n",
    "    \n",
    "    pheno <- read_delim(\"${_input:ar}\")\n",
    "    pheno_NAs <- pheno[, 5:ncol(pheno)]\n",
    "    Yfill <- as.matrix(pheno_NAs)\n",
    "    for (t.row in 1:nrow(pheno_NAs)) {\n",
    "        Yfill[t.row, is.na(Yfill[t.row,])] <- min(Yfill[t.row, ], na.rm = TRUE)\n",
    "    }\n",
    "    write_delim(Yfill, \"${_output:r}\", delim = \"\\t\" )\n",
    "\n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output:n].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `cat $i | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incomplete-audit",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "[bed_filter_na]\n",
    "parameter: rank_max = 50 # max rank estimated in the per-chr methyl matrix\n",
    "parameter: lambda_hyp = 30 # hyper par, indicating the importance of the nuclear norm\n",
    "parameter: impute_method = \"soft\"\n",
    "# Tolerance of missingness rows with missing rate larger than tol_missing will be removed,\n",
    "# with missing rate smaller than tol_missing will be mean_imputed. Say if we want to keep rows with less than 5% missing, then we use 0.05 as tol_missing.\n",
    "parameter: tol_missing = 0.05\n",
    "input: phenoFile\n",
    "output: f'{_input:nn}.filter_na.{impute_method}.bed.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads\n",
    "R: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "   library(\"dplyr\")\n",
    "   library(\"tibble\")\n",
    "   library(\"readr\")\n",
    "   library(softImpute)\n",
    "   compute_missing <- function(mtx){\n",
    "          miss <- sum(is.na(mtx))/length(mtx)\n",
    "          return(miss)\n",
    "        }\n",
    "\n",
    "        mean_impute <- function(mtx){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "    \n",
    "        soft_impute <- function(){\n",
    "          f <- apply(mtx, 2, function(x) mean(x,na.rm = TRUE))\n",
    "          for (i in 1:length(f)) mtx[,i][which(is.na(mtx[,i]))] <- f[i]\n",
    "          return(mtx)\n",
    "        }\n",
    "  \n",
    "  \n",
    "        filter_mtx <- function(X, missing_rate_thresh) {\n",
    "            rm_col <- which(apply(X, 2, compute_missing) > missing_rate_thresh)\n",
    "            if (length(rm_col)) X <- X[, -rm_col]\n",
    "            return((X))\n",
    "        }  \n",
    "  \n",
    "    bed = read_delim(\"${_input}\")\n",
    "    mtx = bed[,5:ncol(bed)]%>%as.matrix\n",
    "    rownames(mtx) = bed[,4]%>%unlist()\n",
    "    tbl_filtered = filter_mtx(mtx%>%t(),${tol_missing})\n",
    "    if ( \"${impute_method}\" == \"mean\" ){\n",
    "    tbl_filtered = tbl_filtered%>%mean_impute()%>%t()\n",
    "     } else if (\"${impute_method}\" == \"soft\"){ \n",
    "      tbl_filtered_C= as(t(tbl_filtered),\"Incomplete\")\n",
    "      fit=softImpute(tbl_filtered_C,rank=${rank_max},lambda=${lambda_hyp},type=\"svd\")\n",
    "      tbl_filtered = complete(t(tbl_filtered),fit)\n",
    "    }\n",
    "    tbl_filtered = tbl_filtered%>%as_tibble(rownames = colnames(bed)[4])  \n",
    "    bed_filtered = inner_join(bed[,1:4],tbl_filtered)\n",
    "    bed_filtered%>%write_delim(\"${_output:n}\", \"\\t\" )\n",
    "  \n",
    "bash: expand= \"${ }\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container=container, entrypoint=entrypoint\n",
    "    bgzip -f ${_output:n}\n",
    "    tabix ${_output}\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint=entrypoint\n",
    "        stdout=$[_output].stdout\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \" >> $stdout;\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"`   >> $stdout;\n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"`   >> $stdout;\n",
    "        echo \"output_column:\" `zcat $i | grep -v \"##\"   | head -1 | wc -w `   >> $stdout;\n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l `   >> $stdout;\n",
    "        echo \"output_preview:\"   >> $stdout;\n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6   >> $stdout ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-minnesota",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "The resource usage for softimputing 450K methylation data are as followed:\n",
    "\n",
    "``` \n",
    "time elapsed: 880.90s\n",
    "peak first occurred: 152.11s\n",
    "peak last occurred: 175.41s\n",
    "max vms_memory: 38.95GB\n",
    "max rss_memory: 34.35GB\n",
    "memory check interval: 1s\n",
    "return code: 0\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.23.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
