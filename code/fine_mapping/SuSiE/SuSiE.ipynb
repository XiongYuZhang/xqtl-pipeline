{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Fine-mapping with individual level data\n",
    "\n",
    "This notebook performs statistical fine-mapping using SuSiE, fSuSiE and mvSuSiE for individual level data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Input\n",
    "\n",
    "1. A list of regions to be analyzed (optional); the last column of this file should be region name.\n",
    "2. A list of genotype files per region to be analyzed, in PLINK `bed` format. \n",
    "3. vector of lists of phenotype files per region to be analyzed, in UCSC `bed.gz` with index in `bed.gz.tbi` formats.\n",
    "4. vector of covariate files corresponding to the lists above.\n",
    "5. Optionally a vector of names of the phenotypic conditions in the form of `cond1 cond2 cond3` separated with whitespace. \n",
    "\n",
    "Input 2 and 3 should be outputs from `genotype_per_region` and `annotate_coord` modules in previous preprocessing steps. 4 should be output of `covariate_preprocessing` pipeline that contains genotype PC, phenotypic hidden confounders and fixed covariates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "### Example genotype list\n",
    "\n",
    "```\n",
    "# region        path\n",
    "ENSG00000000457 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000000457.bed\n",
    "ENSG00000000460 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000000460.bed\n",
    "ENSG00000000938 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000000938.bed\n",
    "ENSG00000000971 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000000971.bed\n",
    "ENSG00000001036 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000001036.bed\n",
    "ENSG00000001084 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000001084.bed\n",
    "ENSG00000001167 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000001167.bed\n",
    "ENSG00000001460 /mnt/mfs/statgen/xqtl_workflow_testing/genotype_per_region/ENSG00000001460.bed\n",
    "```\n",
    "\n",
    "### Example phenotype list\n",
    "\n",
    "```\n",
    "#chr    start   end ID  path\n",
    "chr12   752578  752579  ENSG00000060237  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   990508  990509  ENSG00000082805  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   2794969 2794970 ENSG00000004478  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   4649113 4649114 ENSG00000139180  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6124769 6124770 ENSG00000110799  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "chr12   6534516 6534517 ENSG00000111640  /home/gw/GIT/github/fungen-xqtl-analysis/analysis/Wang_Columbia/ROSMAP/MWE/output/phenotype/protocol_example.protein.bed.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Output\n",
    "\n",
    "For each analysis region, the output is SuSiE model fitted and saved in RDS format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Minimal working example\n",
    "\n",
    "### SuSiE\n",
    "\n",
    "Below we duplicate the examples for phenotype and covariates to demonstrate that when there are multiple phenotypes for the same genotype it is possible to use this pipeline to analyze all of them (more than two is accepted as well)\n",
    "\n",
    "```\n",
    "# suggested output naming convention is cohort_modality, eg ROSMAP_snRNA_pseudobulk\n",
    "sos run pipeline/SuSiE.ipynb susie \\\n",
    "    --name protocol_example_protein \\\n",
    "    --genoFile output/phenotype_by_region/protocol_example.protein.enhanced_cis_chr21_chr22_genotype_by_region/protocol_example.genotype.chr21_22.genotype_by_region_files.txt \\\n",
    "    --phenoFile output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "                output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "    --covFile output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "              output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --phenotype-names A B \\\n",
    "    --container oras://ghcr.io/cumc/stephenslab_apptainer:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "It is also possible to only analyze a selected list of regions by name, using either option `--region-list` or option `--region-name` or both. The command below will include 6 regions to analyze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the data\n",
    "data = {\n",
    "    \"#chr\": [\"chr1\", \"chr1\", \"chr1\"],\n",
    "    \"start\": [1000000, 1010000, 1020000],\n",
    "    \"end\": [1000100, 1010100, 1020100],\n",
    "    \"ID\": [\"ENSG00000159082_O43426\", \"ENSG00000159131_P22102\", \"ENSG00000205726_Q15811\"]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Save the DataFrame to a tab-separated file\n",
    "df.to_csv(\"output/selected_regions.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "source": [
    "```\n",
    "sos run pipeline/SuSiE.ipynb susie \\\n",
    "    --name protocol_example_protein \\\n",
    "    --genoFile output/protocol_example.protein.enhanced_cis_chr21_chr22_genotype_by_region/protocol_example.genotype.chr21_22.genotype_by_region_files.txt\\\n",
    "    --phenoFile output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "                output/phenotype/protocol_example.protein.region_list.txt \\\n",
    "    --covFile output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "              output/covariate/protocol_example.protein.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --phenotype-names A B \\\n",
    "    --cwd output/ \\\n",
    "    --region-list output/selected_regions.tsv \\\n",
    "    --region-name ENSG00000154654_O15394 ENSG00000142192_P05067 ENSG00000159082_O43426 \\\n",
    "    --container oras://ghcr.io/cumc/stephenslab_apptainer:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "### fSuSiE\n",
    "\n",
    "\n",
    "```\n",
    "# suggested output naming convention is cohort_modality, eg ROSMAP_snRNA_pseudobulk\n",
    "sos run pipeline/fSuSiE.ipynb susie \\\n",
    "    --name protocol_example_methylation \\\n",
    "    --genoFile output/phenotype_by_region/protocol_example.methylation.enhanced_cis_chr21_chr22_genotype_by_region/protocol_example.genotype.chr21_22.genotype_by_region_files.txt \\\n",
    "    --phenoFile output/phenotype_by_region/protocol_example.methylation.bed.phenotype_by_region_files.txt \\\n",
    "                output/phenotype_by_region/protocol_example.methylation.bed.phenotype_by_region_files.txt  \\\n",
    "    --covFile output/covariate/protocol_example.methylation.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "              output/covariate/protocol_example.methylation.protocol_example.samples.protocol_example.genotype.chr21_22.pQTL.plink_qc.prune.pca.Marchenko_PC.gz \\\n",
    "    --container oras://ghcr.io/cumc/stephenslab_apptainer:latest\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# A list of file paths for genotype data. \n",
    "parameter: genoFile = path\n",
    "# One or multiple lists of file paths for phenotype data.\n",
    "parameter: phenoFile = paths\n",
    "# Covariate file path\n",
    "parameter: covFile = paths\n",
    "# Optional: if a region list is provide the analysis will be focused on provided region. \n",
    "# The LAST column of this list will contain the ID of regions to focus on\n",
    "# Otherwise, all regions with both genotype and phenotype files will be analyzed\n",
    "parameter: region_list = path()\n",
    "# Optional: if a region name is provided \n",
    "# the analysis would be focused on the union of provides region list and region names\n",
    "parameter: region_name = []\n",
    "parameter: cwd = path(\"output\")\n",
    "# It is required to input the name of the analysis\n",
    "parameter: name = str\n",
    "# path to utility script. In the future we will consolidate this into an R package.\n",
    "parameter: utils_R = path(\"pipeline/xqtl_utils.R\")\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 200\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"20h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 2\n",
    "# Name of phenotypes\n",
    "parameter: phenotype_names = [f'{x:bn}' for x in phenoFile]\n",
    "utils_R = f\"{utils_R:a}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[get_analysis_regions: shared = \"regional_data\"]\n",
    "# input is genoFile, phenoFile, covFile and optionally region_list. If region_list presents then we only analyze what's contained in the list.\n",
    "# regional_data should be a dictionary with:\n",
    "# 1. a list of tuples: {data: [(gene_1.genotype, condition_1, cov_1), (gene_2.genotype, condition_1, cov_1, condition_2, cov_2), ...]} each element may not be of the same length\n",
    "# 2. a list of region meta_info: {meta_info: ( \"chr:start-end\",gene_1,\"cond_1\"), (\"chr:start-end\",gene_2, \"cond_1','cond_2\"), ...]}\n",
    "import pandas as pd\n",
    "import os\n",
    "genoFile = pd.read_csv(genoFile, sep = \"\\t\", header=0)\n",
    "\n",
    "if len(phenoFile) != len(covFile):\n",
    "    raise ValueError(\"Number of input phenotypes files must match that of covariates files\")\n",
    "if len(phenoFile) != len(phenotype_names):\n",
    "    raise ValueError(\"Number of input phenotypes files must match the number of phenotype names\")\n",
    "## pos and covar are condition specific, this way when there is no phenotype file, there is na in the corresponding column.\n",
    "phenoFile = [pd.read_csv(x, sep = \"\\t\", header=0).assign(pos = lambda y:y['#chr']+':'+y['start'].astype(\"str\")+'-'+\n",
    "                                              y['end'].astype(\"str\")).assign(cov_path = z, cond = a ).drop(columns = [\"#chr\",\"start\",\"end\"]).rename(columns = {\"ID\":\"#id\"})   \n",
    "             for x,z,a in zip(phenoFile,covFile,phenotype_names)]\n",
    "for i in range(len(phenoFile)):\n",
    "    genoFile = genoFile.merge(phenoFile[i], on='#id', how='left', suffixes = (f'{i}_x', f'{i}_y'))\n",
    "\n",
    "# remove id that has no phenotype.\n",
    "\n",
    "genoFile = genoFile[~genoFile.drop(columns=['#id',\"#path\"]).isna().all(axis=1)]    \n",
    "\n",
    "if len(genoFile.index) == 0:\n",
    "    raise ValueError(\"No region overlap between genotype #id and any of the phenotypes ID\")\n",
    "\n",
    "# Get position for meta_data\n",
    "pos_col = [col for col in genoFile.columns if col.startswith('pos')]\n",
    "genoFile.index = pd.Series(genoFile[pos_col].values.flatten()).dropna()\n",
    "# Get the conditions strings for each ID\n",
    "cond_col = [col for col in genoFile.columns if col.startswith('cond')]\n",
    "genoFile[\"phenotype_names\"] = [\"','\".join(pd.Series((x)).dropna()) for x in genoFile[cond_col].to_dict(\"split\")[\"data\"]]\n",
    "# Clean up\n",
    "genoFile = genoFile.drop(columns = cond_col).drop(columns = pos_col)\n",
    "\n",
    "\n",
    "region_ids = []\n",
    "\n",
    "# If region_list is provided, read the file and extract IDs\n",
    "if region_list.is_file():\n",
    "    region_list_df = pd.read_csv(region_list, sep = \"\\t\", header=None, comment = \"#\")\n",
    "    region_ids = region_list_df.iloc[:, -1].unique()  # Extracting the last column for IDs\n",
    "\n",
    "# If region_name is provided, include those IDs as well\n",
    "# --region-name A B C will result in a list of [\"A\", \"B\", \"C\"] here\n",
    "if len(region_name) > 0:\n",
    "    region_ids = list(set(region_ids).union(set(region_name)))\n",
    "\n",
    "# If either region_list or region_name is provided, filter the genoFile\n",
    "if region_ids:\n",
    "    genoFile = genoFile[genoFile['#id'].isin(region_ids)]\n",
    "\n",
    "file_inv = genoFile.drop(columns = [\"#id\", \"phenotype_names\"]).to_dict(\"split\")\n",
    "file_inv['data'] = [[value for value in sublist if not pd.isna(value)] for sublist in file_inv['data']] \n",
    "\n",
    "\n",
    "## There will alwayse be genotype file due to left join,\n",
    "## There will alwayse be covar file as len(covFile) must == len(PhenoFile), and covar column is the same string accross all rows\n",
    "## So only if there is no bed.gz there will be problem.\n",
    "regional_data = {\"data\":file_inv[\"data\"],\"meta_info\": genoFile[[\"#id\",\"phenotype_names\"]].reset_index().to_dict(\"split\")['data'] }\n",
    "\n",
    "# Recreate file_inv based on the filtered genoFile\n",
    "file_inv = genoFile.drop(columns=[\"#id\", \"phenotype_names\"]).to_dict(\"split\")\n",
    "file_inv['data'] = [[value for value in sublist if not pd.isna(value)] for sublist in file_inv['data']] \n",
    "\n",
    "# Recreate the regional_data based on the filtered data\n",
    "regional_data = {\"data\": file_inv[\"data\"],\n",
    "                 \"meta_info\": genoFile[[\"#id\", \"phenotype_names\"]].reset_index().to_dict(\"split\")['data']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Univariate SuSiE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[susie_1]\n",
    "parameter: max_L = 20\n",
    "# remove a variant if it has more than imiss missing individual level data\n",
    "parameter: imiss = 1\n",
    "# MAF cutoff\n",
    "parameter: maf = 0.0\n",
    "# MAC cutoff, on top of MAF cutoff\n",
    "# Here I set default to mac = 5 rather than using an MAF cutoff\n",
    "parameter: mac = 5\n",
    "parameter: pip_cutoff = 0.7\n",
    "parameter: coverage = 0.95\n",
    "depends: sos_variable(\"regional_data\")\n",
    "\n",
    "def group_by_region(lst, data):\n",
    "    vector = [len(x) for x in data]\n",
    "    return [lst[sum(vector[:i]):sum(vector[:i+1])] for i in range(len(vector))]\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: f'{cwd:a}/{step_name[:-2]}/{name}.{_meta_info[1]}.susie_fitted.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint, input = utils_R\n",
    "    # Load regional association data\n",
    "    fdat = load_regional_finemapping_data(genotype = ${_input[0]:anr},\n",
    "                                          phenotype = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[1::2]])}),\n",
    "                                          covariate = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[2::2]])}),\n",
    "                                          region = \"${_meta_info[0]}\",\n",
    "                                          conditions = c('${_meta_info[2]}'),\n",
    "                                          maf_cutoff = ${maf},\n",
    "                                          mac_cutoff = ${mac},\n",
    "                                          imiss_cutoff = ${imiss},\n",
    "                                          y_as_matrix = FALSE)\n",
    "    # Fine-mapping with SuSiE\n",
    "    library(susieR)  \n",
    "    fitted = list()\n",
    "    for (r in 1:length(fdat$residual_Y_scaled)) { ## Cant have a universal way to specify names due to the accomodation of missingness, use index instead\n",
    "        st = proc.time()\n",
    "        fitted[[r]] <- susie(fdat$residual_X_scaled[[r]],\n",
    "                             fdat$residual_Y_scaled[[r]],\n",
    "                             L=${max_L},\n",
    "                             max_iter=500,\n",
    "                             estimate_residual_variance=TRUE,\n",
    "                             estimate_prior_variance=TRUE,\n",
    "                             refine=TRUE,\n",
    "                             compute_univariate_zscore=FALSE,\n",
    "                             coverage=${coverage})\n",
    "        fitted[[r]]$analysis_time <- proc.time() - st\n",
    "        fitted[[r]] <- post_process_susie(fitted[[r]], fdat, r, signal_cutoff = ${pip_cutoff})\n",
    "    }\n",
    "    names(fitted) <- names(fdat$residual_Y_scaled)\n",
    "    saveRDS(fitted, ${_output:ar}, compress='xz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Multivariate SuSiE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mvsusie_1]\n",
    "# Prior model file generated from mashr. \n",
    "# Default will be used if it does not exist.\n",
    "parameter: mixture_prior = path()\n",
    "parameter: max_L = 20\n",
    "# remove a variant if it has more than imiss missing individual level data\n",
    "parameter: imiss = 0.1\n",
    "# MAF cutoff\n",
    "parameter: maf = 0.0\n",
    "# MAC cutoff, on top of MAF cutoff\n",
    "# Here I set default to mac = 10 rather than using an MAF cutoff\n",
    "# I don't set it to 5 because I'm not so sure of performance of SuSiE on somewhat infrequent variants\n",
    "# MAC = 10 would not be too infrequenty for xQTL data where sample size is about ~1,000 at most (as of 2022)\n",
    "parameter: mac = 10\n",
    "depends: sos_variable(\"regional_data\")\n",
    "\n",
    "def group_by_region(lst, data):\n",
    "    vector = [len(x) for x in data]\n",
    "    return [lst[sum(vector[:i]):sum(vector[:i+1])] for i in range(len(vector))]\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: f'{cwd:a}/{step_name[:-2]}/{name}.{_meta_info[0]}.susie_fitted.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint, input = utils_R\n",
    "   \n",
    "    get_prior_indices <- function(Y, U) {\n",
    "      # make sure the prior col/rows match the colnames of the Y matrix\n",
    "      y_names = colnames(Y)\n",
    "      u_names = colnames(U)\n",
    "      if (is.null(y_names) || is.null(u_names)) {\n",
    "          return(NULL)\n",
    "      } else if (identical(y_names, u_names)) {\n",
    "          return(NULL)\n",
    "      } else {\n",
    "          return(match(y_names, u_names))\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # Load regional association data\n",
    "    fdat = load_regional_association_data(genotype = ${_input[0]:anr},\n",
    "                                          phenotype = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[1::2]])}),\n",
    "                                          covariate = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[2::2]])}),\n",
    "                                          region = ${'\"%s:%s-%s\"' % (_meta_info[1], _meta_info[2], _meta_info[3])},\n",
    "                                          maf_cutoff = ${maf},\n",
    "                                          mac_cutoff = ${mac},\n",
    "                                          imiss_cutoff = ${imiss},\n",
    "                                          y_as_matrix = TRUE)\n",
    "\n",
    "    # univariate summary statistics\n",
    "    non_missing = lapply(1:ncol(fdat$residual_Y_scaled), function(r)) which(!is.na(fdat$residual_Y_scaled[,r]))\n",
    "    univariate_res = lapply(1:ncol(fdat$residual_Y_scaled), function(r) susieR:::univariate_regression(X[non_missing[[r]], ], fdat$residual_Y_scaled[non_missing[[r]], r]))\n",
    "    sumstat = list(bhat=do.call(cbind, lapply(1:ncol(fdat$residual_Y_scaled), function(r) univariate_res[[r]]$betahat)),\n",
    "                   sbhat=do.call(cbind, lapply(1:ncol(fdat$residual_Y_scaled), function(r) univariate_res[[r]]$sebetahat)))\n",
    "  \n",
    "    # Multivariate fine-mapping\n",
    "    # FIXME: handle it when prior does not exist\n",
    "    prior = readRDS(${mixture_prior:r})\n",
    "    print(paste(\"Number of components in the mixture prior:\", length(prior$U)))\n",
    "    prior = mvsusieR::create_mash_prior(mixture_prior=list(weights=prior$w, matrices=prior$U), include_indices = get_prior_indices(fdat$residual_Y_scaled, prior$U[[1]]), max_mixture_len=-1)   \n",
    "    resid_Y = compute_cov_flash(fdat$residual_Y_scaled)\n",
    "    st = proc.time()\n",
    "    fitted = mvsusieR::mvsusie(fdat$X, \n",
    "                               fdat$residual_Y_scaled, \n",
    "                               L=${max_L}, \n",
    "                               prior_variance=prior, \n",
    "                               residual_variance=resid_Y, \n",
    "                               precompute_covariances=F, \n",
    "                               compute_objective=T, \n",
    "                               estimate_residual_variance=F, \n",
    "                               estimate_prior_variance=T, \n",
    "                               estimate_prior_method='EM',\n",
    "                               max_iter = 200, \n",
    "                               n_thread=${numThreads}, \n",
    "                               approximate=F)\n",
    "    fitted$analysis_time = proc.time() - st\n",
    "    fitted$cs_corr = susieR::get_cs_correlation(fitted, X=fdat$X)\n",
    "    fitted$cs_snps = names(fitted$X_column_scale_factors[unlist(fitted$sets$cs)])\n",
    "    fitted$variable_name = names(fitted$pip)\n",
    "    fitted$analysis_script = load_script()\n",
    "    fitted$dropped_samples = fdat$dropped_sample\n",
    "    fitted$sample_names = colnames(fdat$residual_Y_scaled)\n",
    "    fitted$residual_y = resid_Y\n",
    "    saveRDS(fitted, ${_output:ar})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Univariate fSuSiE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[fsusie_1]\n",
    "parameter: max_L = 30\n",
    "# remove a variant if it has more than imiss missing individual level data\n",
    "parameter: imiss = 0.1\n",
    "# MAF cutoff\n",
    "parameter: maf = 0.0\n",
    "# MAC cutoff, on top of MAF cutoff\n",
    "# Here I set default to mac = 10 rather than using an MAF cutoff\n",
    "# I don't set it to 5 because I'm not so sure of performance of SuSiE on somewhat infrequent variants\n",
    "# MAC = 10 would not be too infrequenty for xQTL data where sample size is about ~1,000 at most (as of 2022)\n",
    "parameter: mac = 10\n",
    "# prior can be either of [\"mixture_normal\", \"mixture_normal_per_scale\"]\n",
    "parameter: prior  = \"mixture_normal_per_scale\"\n",
    "parameter: max_SNP_EM = 1000\n",
    "\n",
    "depends: sos_variable(\"regional_data\")\n",
    "\n",
    "def group_by_region(lst, data):\n",
    "    vector = [len(x) for x in data]\n",
    "    return [lst[sum(vector[:i]):sum(vector[:i+1])] for i in range(len(vector))]\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: f'{cwd:a}/{step_name[:-2]}/{name}.{_meta_info[0]}.fsusie_{prior}.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint, input = utils_R\n",
    "    # Load regional association data\n",
    "    fdat = load_regional_association_data(genotype = ${_input[0]:anr},\n",
    "                                          phenotype = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[1::2]])}),\n",
    "                                          covariate = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[2::2]])}),\n",
    "                                          region = ${'\"%s:%s-%s\"' % (_meta_info[1], _meta_info[2], _meta_info[3])},\n",
    "                                          maf_cutoff = ${maf},\n",
    "                                          mac_cutoff = ${mac},\n",
    "                                          imiss_cutoff = ${imiss},\n",
    "                                          y_as_matrix = FALSE)\n",
    "    # Fine-mapping with fSuSiE\n",
    "    library(\"susiF.alpha\")\n",
    "    fitted = list()\n",
    "    for (r in 1:length(fdat$residual_Y_scaled)) {\n",
    "        st = proc.time()  \n",
    "        fitted[[r]] <- susiF(fdat$residual_X_scaled[[r]],\n",
    "                             fdat$residual_Y_scaled[[r]],\n",
    "                             pos=fdat$phenotype_coordiates[[r]], #FIXME: this needs to be edited and added dto load_regional_association_data\n",
    "                             L=${max_L},\n",
    "                             prior=\"${prior}\",\n",
    "                             max_SNP_EM=${max_SNP_EM})\n",
    "        fitted[[r]]$analysis_time = proc.time() - st\n",
    "        fitted[[r]]$cs_corr = get_cs_correlation(fitted[[r]], X=fdat$residual_X_scaled[[r]])\n",
    "        fitted[[r]]$cs_snps = names(fitted[[r]]$X_column_scale_factors[unlist(fitted[[r]]$sets$cs)])\n",
    "        fitted[[r]]$variable_name = names(fitted[[r]]$pip)\n",
    "        fitted[[r]]$coef = coef.susie(fitted[[r]])\n",
    "        fitted[[r]]$analysis_script = load_script()\n",
    "        fitted[[r]]$analysis_name = fdat$traits[[r]]\n",
    "        fitted[[r]]$dropped_samples = fdat$dropped_sample[[r]]\n",
    "        fitted[[r]]$sample_names = colnames(fdat$residual_Y_scaled[[r]])\n",
    "    }\n",
    "    saveRDS(fitted, ${_output:ar})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Multivariate fSuSiE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[mvfsusie_1]\n",
    "parameter: max_L = 30\n",
    "# remove a variant if it has more than imiss missing individual level data\n",
    "parameter: imiss = 0.1\n",
    "# MAF cutoff\n",
    "parameter: maf = 0.0\n",
    "# MAC cutoff, on top of MAF cutoff\n",
    "# Here I set default to mac = 10 rather than using an MAF cutoff\n",
    "# I don't set it to 5 because I'm not so sure of performance of SuSiE on somewhat infrequent variants\n",
    "# MAC = 10 would not be too infrequenty for xQTL data where sample size is about ~1,000 at most (as of 2022)\n",
    "parameter: mac = 10\n",
    "# prior can be either of [\"mixture_normal\", \"mixture_normal_per_scale\"]\n",
    "parameter: prior  = \"mixture_normal_per_scale\"\n",
    "parameter: max_SNP_EM = 1000\n",
    "\n",
    "depends: sos_variable(\"regional_data\")\n",
    "\n",
    "def group_by_region(lst, data):\n",
    "    vector = [len(x) for x in data]\n",
    "    return [lst[sum(vector[:i]):sum(vector[:i+1])] for i in range(len(vector))]\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: f'{cwd:a}/{step_name[:-2]}/{name}.{_meta_info[0]}.mvfsusie_{prior}.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint, input = utils_R\n",
    "    # Load regional association data\n",
    "    fdat = load_regional_association_data(genotype = ${_input[0]:anr},\n",
    "                                          phenotype = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[1::2]])}),\n",
    "                                          covariate = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[2::2]])}),\n",
    "                                          region = ${'\"%s:%s-%s\"' % (_meta_info[1], _meta_info[2], _meta_info[3])},\n",
    "                                          maf_cutoff = ${maf},\n",
    "                                          mac_cutoff = ${mac},\n",
    "                                          imiss_cutoff = ${imiss},\n",
    "                                          y_as_matrix = FALSE)\n",
    "    # Fine-mapping with mvfSuSiE\n",
    "    library(\"mvf.susie.alpha\")\n",
    "    Y = map(fdat$residual_Y_scaled, ~left_join(fdat$X[,1]%>%as.data.frame%>%rownames_to_column(\"rowname\"), .x%>%t%>%as.data.frame%>%rownames_to_column(\"rowname\") , by = \"rowname\")%>%select(-2)%>%column_to_rownames(\"rowname\")%>%as.matrix )\n",
    "    fitted <- multfsusie(Y_f = list(Y[[1]],Y[[3]]), \n",
    "                         Y_u = Reduce(cbind, Y[[2]]),\n",
    "                         pos = list(pos1 =fdat$phenotype_coordiates[[1]], pos2 = fdat$phenotype_coordiates[[3]]),\n",
    "                         X=X,\n",
    "                         L=${max_L},\n",
    "                         data.format=\"list_df\")\n",
    "    saveRDS(fitted, ${_output:ar})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[*_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.susie_output.txt'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout', container = container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"output\" : [$[_input:ar,]]}).to_csv(\"$[_output]\",index = False ,header = False, sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "SoS",
     "sos",
     "",
     ""
    ]
   ],
   "version": "0.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
