{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# TensorQTL QTL association testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "This notebook implements a workflow using [tensorQTL](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1836-7) to perform QTL association testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- List of molecular phenotype files: a list of `bed.gz` files containing the table for the molecular phenotype. It should have a companion index file in `tbi` format.\n",
    "\n",
    "    The header of the bed.gz is per the [TensorQTL](https://github.com/broadinstitute/tensorqtl) convention:\n",
    "\n",
    "    >    Phenotypes must be provided in BED format, with a single header line starting with # and the first four columns corresponding to: chr, start, end, phenotype_id, with the remaining columns corresponding to samples (the identifiers must match those in the genotype input). The BED file should specify the center of the cis-window (usually the TSS), with start == end-1.\n",
    "\n",
    "\n",
    "- List of genotypes in PLINK binary format (`bed`/`bim`/`fam`) for each chromosome, previously processed through our genotype QC pipelines.\n",
    "- Covariate file, a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "- Optionally, a list of traits (genes, regions of molecular features etc) to analyze.\n",
    "\n",
    "For cis-analysis:\n",
    "\n",
    "- Optionally, a list of genomic regions associate with each molecular features to analyze. The default cis-analysis will use a window around TSS. This can be customized to take given start and end genomic coordinates.\n",
    "\n",
    "\n",
    "## Output\n",
    "\n",
    "For each chromosome, several of summary statistics files are generated, including both nominal test statistics for each test, as well as region (gene) level association evidence.\n",
    "\n",
    "The columns of nominal association result are as follows:\n",
    "\n",
    "- phenotype_id: Molecular trait identifier.(gene)\n",
    "- variant_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance: Distance of the SNP to the gene transcription start site (TSS)\n",
    "- af: The allele frequency of this SNPs\n",
    "- ma_samples: Number of samples carrying the minor allele\n",
    "- ma_count: Total number of minor alleles across individuals\n",
    "- pval: Nominal P-value from linear regression\n",
    "- beta: Slope of the linear regression\n",
    "- se: Standard error of beta\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "\n",
    "\n",
    "The column specification of region (gene) level association evidence are as follows:\n",
    "\n",
    "- phenotype_id - Molecular trait identifier. (gene)\n",
    "- num_var - Total number of variants tested in cis\n",
    "- beta_shape1 - First parameter value of the fitted beta distribution\n",
    "- beta_shape2 - Second parameter value of the fitted beta distribution\n",
    "- true_df - Effective degrees of freedom the beta distribution approximation\n",
    "- pval_true_df - Empirical P-value for the beta distribution approximation\n",
    "- variant_id - ID of the top variant (rsid or chr:position:ref:alt)\n",
    "- tss_distance - Distance of the SNP to the gene transcription start site (TSS)\n",
    "- ma_samples - Number of samples carrying the minor allele\n",
    "- ma_count - Total number of minor alleles across individuals\n",
    "- maf - Minor allele frequency in MiGA cohort\n",
    "- ref_factor - Flag indicating if the alternative allele is the minor allele in the cohort (1 if AF <= 0.5, -1 if not)\n",
    "- pval_nominal - Nominal P-value from linear regression\n",
    "- slope - Slope of the linear regression\n",
    "- slope_se - Standard error of the slope\n",
    "- pval_perm - First permutation P-value directly obtained from the permutations with the direct method\n",
    "- pval_beta - Second permutation P-value obtained via beta approximation. This is the one to use for downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run TensorQTL.ipynb [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  cis\n",
      "  trans\n",
      "\n",
      "Global Workflow Options:\n",
      "  --covariate-file VAL (as path, required)\n",
      "                        Covariate file\n",
      "  --genotype-file VAL (as path, required)\n",
      "                        For cis, genotype file in PLINK binary format\n",
      "                        (bed/bam/fam) format, per chrom, for trans, 1 whole\n",
      "                        genome genotype file in plink binary format\n",
      "  --region-list . (as path)\n",
      "                        An optional subset of regions of molecular features to\n",
      "                        analyze\n",
      "  --customized-cis-windows . (as path)\n",
      "                        An optional list documenting the custom cis window for\n",
      "                        each region to analyze, with four column, chr, start,\n",
      "                        end, region ID (eg gene ID). If this list is not\n",
      "                        provided, the default `window` parameter (see below)\n",
      "                        will be used.\n",
      "  --cwd output (as path)\n",
      "                        Path to the work directory of the analysis.\n",
      "  --phenotype-file VAL (as path, required)\n",
      "                        Phenotype file, if cis a list of phenotype per chrom, if\n",
      "                        trans, 1 whole genome phenotype file.\n",
      "  --name  f\"{phenotype_file:bn}_{covariate_file:bn}\"\n",
      "\n",
      "                        Prefix for the analysis output\n",
      "  --MAC 0 (as int)\n",
      "                        Minor allele count cutoff\n",
      "  --region-name 'gene_id'\n",
      "                        The name of phenotype corresponding to gene_id or\n",
      "                        gene_name in the region\n",
      "  --phenotype-group . (as path)\n",
      "                        The phenotype group file to group molecule_trait into\n",
      "                        molecule_trait_object This is applicable to when there\n",
      "                        are multiple molecular events in the same region, such\n",
      "                        as sQTL analysis.\n",
      "  --window 1000000 (as int)\n",
      "                        Specify the cis window for the up and downstream radius\n",
      "                        to analyze around the region of interest, in units of bp\n",
      "                        This parameter will be set to zero if\n",
      "                        `customized_cis_windows` is provided.\n",
      "  --numThreads 8 (as int)\n",
      "                        Number of threads\n",
      "  --job-size 1 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 12h\n",
      "  --mem 16G\n",
      "  --container ''\n",
      "                        Container option for software to run the analysis:\n",
      "                        docker or singularity\n",
      "  --entrypoint {('micromamba run -a \"\" -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
      "\n",
      "  --maf-threshold  MAC/(2.0*N)\n",
      "\n",
      "                        Minor allele frequency cutoff. It will overwrite minor\n",
      "                        allele cutoff.\n",
      "\n",
      "Sections\n",
      "  cis_1:\n",
      "    Workflow Options:\n",
      "      --skip-nominal-if-exist  false\n",
      "\n",
      "                        skip nominal association results if the files exists\n",
      "                        already This is false by default which means to\n",
      "                        recompute everything This is only relevant when the\n",
      "                        `parquet` files for nominal results exist but not the\n",
      "                        other files and you want to avoid computing the nominal\n",
      "                        results again\n",
      "  trans_1:\n",
      "    Workflow Options:\n",
      "      --batch-size 50000 (as int)\n",
      "      --pval-threshold 1.0 (as float)\n",
      "  cis_2:\n",
      "  trans_2:\n"
     ]
    }
   ],
   "source": [
    "sos run TensorQTL.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## Minimal working example\n",
    "\n",
    "An MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1yjTwoO0DYGi-J9ouMsh9fHKfDmsXJ_4I?usp=sharing).\n",
    "The singularity image (sif) for running this MWE is uploaded to [google drive](https://drive.google.com/drive/folders/1mLOS3AVQM8yTaWtCbO8Q3xla98Nr5bZQ)\n",
    "\n",
    "FIXME: need to update these links. \n",
    "\n",
    "FIXME: Also need to update the example commands below using our new example dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb cis \\\n",
    "    --genotype-file plink_files_list.txt \\\n",
    "    --phenotype-file MWE.bed.recipe \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd ./output/ \\\n",
    "    --container containers/TensorQTL.sif --MAC 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file MWE.bed \\\n",
    "    --phenotype-file MWE.log2cpm.mol_phe.bed.gz \\\n",
    "    --covariate-file ALL.covariate.pca.BiCV.cov.gz \\\n",
    "    --cwd ./output/ \\\n",
    "    --container containers/TensorQTL.sif --MAC 5 --region-name  gene_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "Bash"
   },
   "outputs": [],
   "source": [
    "sos run pipeline/TensorQTL.ipynb trans \\\n",
    "    --genotype-file /mnt/vast/hpc/csg/snuc_pseudo_bulk/data/genotype_qced/GRCh38_liftedover_sorted_all.add_chr.leftnorm.filtered.renamed.filtered.renamed.filtered.filtered.bed \\\n",
    "    --phenotype-file /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_tissue_analysis/output/data_preprocessing/ALL/phenotype_data/ALL.log2cpm.bed.gz \\\n",
    "    --covariate-file /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_tissue_analysis/output/data_preprocessing/ALL/covariates/ALL.log2cpm.ALL.covariate.pca.resid.PEER.cov.gz \\\n",
    "    --cwd ./output/trans_tensorQTL/ \\\n",
    "    --region-list /mnt/vast/hpc/csg/snuc_pseudo_bulk/eight_tissue_analysis/reference_data/AD_genes.region_list \\\n",
    "    --container containers/TensorQTL.sif --MAC 5 --region-name ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# Covariate file\n",
    "parameter: covariate_file = path\n",
    "# For cis, genotype file in PLINK binary format (bed/bam/fam) format, per chrom, for trans, 1 whole genome genotype file in plink binary format\n",
    "parameter: genotype_file = path\n",
    "# An optional subset of regions of molecular features to analyze. The last column is the  gene names\n",
    "parameter: region_list = path()\n",
    "# An optional list documenting the custom cis window for each region to analyze, with four column, chr, start, end, region ID (eg gene ID).\n",
    "# If this list is not provided, the default `window` parameter (see below) will be used.\n",
    "parameter: customized_cis_windows = path()\n",
    "# Path to the work directory of the analysis.\n",
    "parameter: cwd = path('output')\n",
    "# Phenotype file, if cis a list of phenotype per chrom, if trans, 1 whole genome phenotype file.\n",
    "parameter: phenotype_file = path\n",
    "# Prefix for the analysis output\n",
    "parameter: name = f\"{phenotype_file:bn}_{covariate_file:bn}\"\n",
    "# Minor allele count cutoff\n",
    "parameter: MAC = 0\n",
    "# The name of phenotype corresponding to gene_id or gene_name in the region\n",
    "parameter: region_name = \"gene_id\"\n",
    "# The phenotype group file to group molecule_trait into molecule_trait_object\n",
    "# This is applicable to when there are multiple molecular events in the same region, such as sQTL analysis.\n",
    "parameter: phenotype_group = path() \n",
    "\n",
    "# Specify the cis window for the up and downstream radius to analyze around the region of interest, in units of bp\n",
    "# This parameter will be set to zero if `customized_cis_windows` is provided.\n",
    "parameter: window = 1000000\n",
    "\n",
    "# Number of threads\n",
    "parameter: numThreads = 8\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 1\n",
    "parameter: walltime = '12h'\n",
    "parameter: mem = '16G'\n",
    "# Container option for software to run the analysis: docker or singularity\n",
    "parameter: container = ''\n",
    "parameter: entrypoint={('micromamba run -a \"\" -n' + ' ' + container.split('/')[-1][:-4]) if container.endswith('.sif') else f''}\n",
    "\n",
    "# Use the header of covariate file to decide the sample size\n",
    "import pandas as pd\n",
    "N = len(pd.read_csv(covariate_file, sep = \"\\t\",nrows = 1).columns) - 1\n",
    "\n",
    "# Minor allele frequency cutoff. It will overwrite minor allele cutoff.\n",
    "parameter: maf_threshold = MAC/(2.0*N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "Bash"
   },
   "source": [
    "## cis-xQTL association testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_1]\n",
    "# parse input file lists\n",
    "import pandas as pd\n",
    "molecular_pheno_files = pd.read_csv(phenotype_file, sep = \"\\t\")\n",
    "genotype_files = pd.read_csv(genotype_file,sep = \"\\t\")\n",
    "genotype_files[\"#id\"] = genotype_files[\"#id\"].astype(str)\n",
    "molecular_pheno_files[\"#id\"] = molecular_pheno_files[\"#id\"].astype(str)\n",
    "\n",
    "input_files = molecular_pheno_files.merge(genotype_files, on = \"#id\")\n",
    "input_files = input_files.values.tolist()\n",
    "input_chroms = [x[0] for x in input_files]\n",
    "input_files = [x[1:] for x in input_files]\n",
    "\n",
    "# skip nominal association results if the files exists already\n",
    "# This is false by default which means to recompute everything\n",
    "# This is only relevant when the `parquet` files for nominal results exist but not the other files\n",
    "# and you want to avoid computing the nominal results again\n",
    "parameter: skip_nominal_if_exist = False\n",
    "input: input_files, group_by = len(input_files[0]), group_with = \"input_chroms\" \n",
    "output: parquet = f'{cwd:a}/{name}.cis_qtl_pairs.{_input_chroms}.parquet', # This convention is necessary to match the pattern of map_norminal output\n",
    "        regional = f'{cwd:a}/{name}.{_input_chroms}.cis_qtl_regional.gz',\n",
    "        nominal = f'{cwd:a}/{name}.{_input_chroms}.cis_qtl_nominal.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout' , container = container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis, trans\n",
    "    from scipy.stats import chi2\n",
    "        \n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    ## Load Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\", comment=\"#\", header=None, sep=\"\\t\")\n",
    "        keep_region = region.iloc[:, -1].to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "    ## use custom cis windows\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        phenotype_pos_df = phenotype_pos_df.reset_index() #move the phenotype id index to a new column of the dataframe\n",
    "        phenotype_pos_df = phenotype_pos_df.merge(cis_list, left_on = [\"chr\",phenotype_id],right_on = [cis_list.columns[0],cis_list.columns[3]])#in some cases (gene expression for eQTLs) the phenotype_id may be in the cis_list file\n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]] # The final phenotype_pos_df will have three columns(chr, start, end) and index is the phenotype ID\n",
    "        if len(phenotype_df.index) != len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        window = 0 # In the updated tensorQTL, by default if there is a customized cis window, the actual cis window will be start - window & end + window, so it is necessary to change the window parameter to 0\n",
    "    \n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    \n",
    "    ## To simplify things, there should really not be \"chr\" prefix\n",
    "    phenotype_pos_df.chr = [x.replace(\"chr\",\"\") for x in phenotype_pos_df.chr]\n",
    "    variant_df.chrom = [x.replace(\"chr\",\"\") for x in variant_df.chrom]\n",
    "    ## Read phenotype group if availble\n",
    "    if $[phenotype_group.is_file()]:\n",
    "        group_s = pd.read_csv($[phenotype_group:r], sep='\\t', header=None, index_col=0, squeeze=True)\n",
    "    else:\n",
    "        group_s = None\n",
    "\n",
    "    ## cis-QTL mapping: nominal associations for all variant-phenotype pairs\n",
    "    if not ($[skip_nominal_if_exist] and $[_output[0].is_file()]):\n",
    "        cis.map_nominal(genotype_df, variant_df,\n",
    "                phenotype_df,\n",
    "                phenotype_pos_df,\n",
    "                \"$[_output[0]:nnn]\", \n",
    "                covariates_df=covariates_df, \n",
    "                window=window, \n",
    "                maf_threshold = $[maf_threshold],\n",
    "                group_s=group_s)\n",
    "\n",
    "    ## Load the parquet and save it as txt\n",
    "    pairs_df = pd.read_parquet(\"$[_output[0]]\")\n",
    "    ## Adds the group columns to pairs_df, if there is group_s use group_s, else use phenotype_id\n",
    "    if group_s is not None:\n",
    "        pairs_df = pairs_df.merge(pd.DataFrame( {\"molecular_trait_object_id\": group_s}),left_on = \"phenotype_id\", right_index = True)\n",
    "    else:\n",
    "        pairs_df[\"molecular_trait_object_id\"] = pairs_df.phenotype_id\n",
    "\n",
    "    # genomic inflation factor lambda\n",
    "    lambda_col = pairs_df.groupby(\"molecular_trait_object_id\").apply( lambda x:  chi2.ppf(1. - np.median(x.pval_nominal), 1)/chi2.ppf(0.5,1))\n",
    "    pairs_df.columns.values[0]  = \"molecular_trait_id\"\n",
    "    pairs_df.columns.values[6]  = \"pvalue\"\n",
    "    pairs_df.columns.values[7]  = \"beta\"\n",
    "    pairs_df.columns.values[8]  = \"se\"\n",
    "    pairs_df = pairs_df.assign(maf = lambda dataframe: dataframe['af'].map(lambda af:af if af < 0.5 else 1-af) ).drop(\"af\",axis =  1)\n",
    "    pairs_df[\"n\"] = len(phenotype_df.columns.values)\n",
    "    pairs_df = pairs_df.assign(\n",
    "    alt = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[-1])).assign(\n",
    "    ref = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[-2])).assign(\n",
    "    pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0].split(\":\")[1])).assign(\n",
    "    chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0]))\n",
    "    pairs_df.to_csv(\"$[_output[2]]\", sep='\\t',index = None, compression='gzip')\n",
    "    cis_df = cis.map_cis(genotype_df, \n",
    "                        variant_df, \n",
    "                        phenotype_df,\n",
    "                        phenotype_pos_df,\n",
    "                        covariates_df=covariates_df, \n",
    "                        seed=999, \n",
    "                        window=$[window], \n",
    "                        maf_threshold = $[maf_threshold],\n",
    "                        group_s=group_s)\n",
    "    \n",
    "    cis_df.index.name = \"molecular_trait_id\"\n",
    "    ## Add groups columns for eQTL analysis\n",
    "    if \"group_id\" not in cis_df.columns:\n",
    "        cis_df[\"group_id\"] = cis_df.index\n",
    "        cis_df[\"group_size\"] = 1\n",
    "    cis_df = cis_df.rename({\"group_id\":\"molecular_trait_object_id\",\"group_size\":\"n_traits\",\"num_var\" : \"n_variants\",\"variant_id\":\"variant\",\"pval_perm\":\"p_perm\", \"pval_beta\":\"p_beta\" },axis = 1)\n",
    "    cis_df = cis_df.assign(genomic_inflation = lambda dataframe : dataframe[\"molecular_trait_object_id\"].map(lambda molecular_trait_object_id:lambda_col[molecular_trait_object_id]))\n",
    "    cis_df.to_csv(\"$[_output[1]]\", sep='\\t', compression='gzip')\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, entrypoint = entrypoint\n",
    "        for i in $[_output[0]] ; do \n",
    "        echo \"output_info: $i \"\n",
    "        echo \"This is the file containing the immediate output of TensorQTL's map_nominal function \"\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"` \n",
    "        done\n",
    "        for i in $[_output[1]] ; do \n",
    "        echo \"output_info: $i \" \n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"` \n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"` \n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l ` \n",
    "        echo \"output_column:\" `zcat $i | grep -V \"##\" | head -1 | wc -w `\n",
    "        echo \"output_preview:\"\n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6,7,8,9,10  ; done\n",
    "        for i in $[_output[2]] ; do \n",
    "        echo \"output_info: $i \"\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"` \n",
    "        echo \"output_rows:\" `zcat $i | wc -l  | cut -f 1 -d \" \"` \n",
    "        echo \"output_headerow:\" `zcat $i | grep \"##\" | wc -l `\n",
    "        echo \"output_column:\" `zcat $i | grep -V \"##\" | head -1 | wc -w `\n",
    "        echo \"output_preview:\" \n",
    "        zcat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6,7,8,9,10 ; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## TransQTL association testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "For transQTL analysis, it is suggested to provide the largest memory and CPU threads available on a compute node. eg 250G and >32 threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[trans_1]\n",
    "fail_if(not region_list.is_file(), msg = \"For trans analysis, ``region_list`` must be provided.\")\n",
    "parameter: permutation_batch_size = 50000\n",
    "parameter: pval_threshold = 1.0\n",
    "parameter: permutation = False\n",
    "input: phenotype_file, genotype_file \n",
    "output: nominal = f'{cwd:a}/{_input[0]:bnn}.trans_qtl_nominal.gz'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container =container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import tensorqtl\n",
    "    from tensorqtl import genotypeio, cis, trans\n",
    "    ## Define paths\n",
    "    plink_prefix_path = $[_input[1]:nar]\n",
    "    expression_bed = $[_input[0]:ar]\n",
    "    covariates_file = \"$[covariate_file:a]\"\n",
    "    window = $[window]\n",
    "    ## Loading Data\n",
    "    phenotype_df, phenotype_pos_df = tensorqtl.read_phenotype_bed(expression_bed)\n",
    "    phenotype_id = phenotype_pos_df.index.name\n",
    "    ## Analyze only the regions listed\n",
    "    if $[region_list.is_file()]:\n",
    "        region = pd.read_csv(\"$[region_list:a]\", comment=\"#\", header=None, sep=\"\\t\")\n",
    "        keep_region = region.iloc[:, -1].to_list()\n",
    "        phenotype_df = phenotype_df[phenotype_df.index.isin(keep_region)]\n",
    "        phenotype_pos_df = phenotype_pos_df[phenotype_pos_df.index.isin(keep_region)]\n",
    "    ## use custom cis windows\n",
    "    if $[customized_cis_windows.is_file()]:\n",
    "        cis_list = pd.read_csv(\"$[customized_cis_windows:a]\", comment=\"#\", header=None, names=[\"chr\",\"start\",\"end\",phenotype_id], sep=\"\\t\")\n",
    "        phenotype_pos_df = phenotype_pos_df.reset_index() #move the phenotype id index to a new column of the dataframe\n",
    "        phenotype_pos_df = phenotype_pos_df.merge(cis_list, left_on = [\"chr\",phenotype_id],right_on = [cis_list.columns[0],cis_list.columns[3]])#in some cases (gene expression for eQTLs) the phenotype_id may be in the cis_list file\n",
    "        phenotype_pos_df = phenotype_pos_df.set_index(phenotype_id)[[\"chr\",\"start\",\"end\"]] # The final phenotype_pos_df will have three columns(chr, start, end) and index is the phenotype ID\n",
    "        if len(phenotype_df.index) != len(phenotype_pos_df.index):\n",
    "            raise ValueError(\"cannot uniquely match all the phentoype data in the input to the customized cis windows provided\")\n",
    "        window = 0 # In the updated tensorQTL, by default if there is a customized cis window, the actual cis window will be start - window & end + window, so it is necessary to change the window parameter to 0\n",
    "    \n",
    "    covariates_df = pd.read_csv(covariates_file, sep='\\t', index_col=0).T\n",
    "    pr = genotypeio.PlinkReader(plink_prefix_path)\n",
    "    genotype_df = pr.load_genotypes()\n",
    "    variant_df = pr.bim.set_index('snp')[['chrom', 'pos']]\n",
    "    ## Retaining only common samples\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, covariates_df.index)]\n",
    "    phenotype_df = phenotype_df[np.intersect1d(phenotype_df.columns, genotype_df.columns)]\n",
    "    covariates_df = covariates_df.transpose()[np.intersect1d(phenotype_df.columns, covariates_df.index)].transpose()\n",
    "    ## Trans analysis\n",
    "    trans_df = trans.map_trans(genotype_df, \n",
    "                            phenotype_df,\n",
    "                            covariates_df, \n",
    "                            batch_size=$[permutation_batch_size],\n",
    "                            return_sparse=True, \n",
    "                            return_r2 = True, \n",
    "                            pval_threshold=$[pval_threshold], \n",
    "                            maf_threshold=$[maf_threshold])\n",
    "    ## Filter out cis signal, again if customized cis windows are used, the windows is [start-win,end + win] where win = 0, else it is [start - win, start + win]\n",
    "    trans_df = trans.filter_cis(trans_df, phenotype_pos_df, variant_df, window=window)   \n",
    "    ## Permutation\n",
    "    if $[\"True\" if permutation else \"False\"]:\n",
    "        perm_df = trans.map_permutations(genotype_df, covariates_df, batch_size=$[permutation_batch_size],\n",
    "                             maf_threshold=$[maf_threshold])\n",
    "        perm_output = trans.apply_permutations(perm_df,trans_df)\n",
    "    ## Output\n",
    "    trans_df.columns.values[1]  = \"molecular_trait_id\"\n",
    "    trans_df.columns.values[2]  = \"pvalue\"\n",
    "    trans_df.columns.values[3]  = \"beta\"\n",
    "    trans_df.columns.values[4]  = \"se\"\n",
    "    trans_df = trans_df.assign(maf = lambda dataframe: dataframe['af'].map(lambda af:af if af < 0.5 else 1-af) ).drop(\"af\",axis =  1)\n",
    "    trans_df = trans_df.assign(\n",
    "    chrom = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\":\")[0])).assign(\n",
    "    alt = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[2])).assign(\n",
    "    ref = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[1])).assign(\n",
    "    pos = lambda dataframe: dataframe['variant_id'].map(lambda variant_id:variant_id.split(\"_\")[0]))\n",
    "    trans_df.to_csv(\"$[_output]\", sep='\\t',index = None)\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, entrypoint = entrypoint\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \"\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"` \n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l ` \n",
    "        echo \"output_column:\" `cat $i | grep -V \"##\" | head -1 | wc -w ` \n",
    "        echo \"output_preview:\" \n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6,7,8,9,10; done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Association results processing\n",
    "For both cis and trans: Generate the recipe for yml processing\n",
    "For cis: Also process the consolidates emprical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[cis_2]\n",
    "input:  group_by = \"all\"\n",
    "output: f'{_input[\"nominal\"][0]:nnn}.cis_qtl.meta_info',\n",
    "        f'{_input[\"nominal\"][0]:nnn}.cis_qtl.column_info',\n",
    "        f'{_input[\"regional\"][0]:nnn}.fdr.gz',\n",
    "        f'{_input[\"regional\"][0]:nnn}.summary.txt'   \n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container = container, entrypoint = entrypoint\n",
    "    import pandas as pd\n",
    "\n",
    "    data_temp = pd.DataFrame({\n",
    "    \"sumstat_dir\" : [$[_input[\"regional\"]:r,]],\n",
    "    \"column_info\" : $[_output[1]:r]\n",
    "    })\n",
    "    column_info_df = pd.DataFrame( pd.Series( {\"ID\": \"molecular_trait_id,chromosome,position,ref,alt\",\n",
    "      \"chromosome\": \"chrom\",\n",
    "      \"position\": \"pos\",\n",
    "      \"variant\": \"variant_id\",\n",
    "      \"ref\": \"ref\",\n",
    "      \"alt\": \"alt\",\n",
    "      \"beta\": \"beta\",\n",
    "      \"se\": \"se\",\n",
    "      \"pvalue\": \"pvalue\",\n",
    "      \"TSS_D\": \"tss_distance\",\n",
    "      \"maf\": \"maf\",\n",
    "      \"n\" : \"n\" ,\n",
    "      \"ma_samples\": \"ma_samples\",\n",
    "      \"ac\": \"ma_count\",\n",
    "      \"molecular_trait_id\": \"molecular_trait_id\", \n",
    "      \"molecular_trait_object_id\": \"molecular_trait_object_id\"}), columns = [\"TensorQTL\"] )\n",
    "\n",
    "    data_temp[\"#chr\"] = [x.split(\".\")[-3].replace(\"chr\",\"\") for x in  [$[_input[\"nominal\"]:r,]]]\n",
    "    data_temp = data_temp[['#chr', 'sumstat_dir', 'column_info']]\n",
    "    data_temp.to_csv(\"$[_output[0]]\",index = False,sep = \"\\t\" )\n",
    "    column_info_df.to_csv(\"$[_output[1]]\",index = True,sep = \"\\t\" )\n",
    "\n",
    "R: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout',container =container, entrypoint = entrypoint \n",
    "    library(\"purrr\")\n",
    "    library(\"tidyr\")\n",
    "    library(\"dplyr\")\n",
    "    library(\"readr\")\n",
    "    library(\"qvalue\")\n",
    "    emprical_pd = tibble(map(c($[_input[\"regional\"]:r,]), ~read_delim(.x,\"\\t\")))%>%unnest()\n",
    "    emprical_pd[\"q_beta\"] = tryCatch(qvalue(emprical_pd$p_beta)$qvalue, error = function(e){print(\"Too few pvalue to calculate qvalue, fall back to BH\") \n",
    "                                                                                              qvalue(emprical_pd$p_beta,pi0 = 1 )$qvalue})  \n",
    "\n",
    "    emprical_pd[\"q_perm\"] = tryCatch(qvalue(emprical_pd$p_perm)$qvalue, error = function(e){print(\"Too few pvalue to calculate qvalue, fall back to BH\") \n",
    "                                                                                              qvalue(emprical_pd$p_perm,pi0 = 1 )$qvalue})\n",
    "    emprical_pd[\"fdr_beta\"] = p.adjust(emprical_pd$p_beta,\"fdr\")    \n",
    "    emprical_pd[\"fdr_perm\"] = p.adjust(emprical_pd$p_perm,\"fdr\")    \n",
    "    summary = tibble(\"fdr_perm_0.05\" =  sum(emprical_pd[\"fdr_perm\"] < 0.05) , \n",
    "                      \"fdr_beta_0.05\" = sum(emprical_pd[\"fdr_beta\"] < 0.05),\n",
    "                      \"q_perm_0.05\" = sum(emprical_pd[\"q_perm\"] < 0.05) ,\n",
    "                      \"q_beta_0.05\" = sum(emprical_pd[\"q_beta\"] < 0.05) ,\n",
    "                       \"q_perm_0.01\" = sum(emprical_pd[\"q_perm\"] < 0.01) ,\n",
    "                      \"q_beta_0.01\" = sum(emprical_pd[\"q_beta\"] < 0.01)  )\n",
    "    emprical_pd%>%write_delim(\"$[_output[2]]\",\"\\t\")\n",
    "    summary%>%write_delim(\"$[_output[3]]\",\"\\t\")\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, entrypoint = entrypoint\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \"\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"` \n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"`\n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l `\n",
    "        echo \"output_column:\" `cat $i | grep -V \"##\" | head -1 | wc -w `\n",
    "        echo \"output_preview:\"\n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6,7,8,9,10 ; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "kernel": "SoS"
   },
   "outputs": [],
   "source": [
    "[trans_2]\n",
    "input:  group_by = \"all\"\n",
    "output: f'{_input[\"nominal\"]:nn}.trans_qtl.meta_info',\n",
    "        f'{_input[\"nominal\"]:nn}.trans_qtl.column_info'\n",
    "python: expand = \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, entrypoint = entrypoint\n",
    "    import pandas as pd \n",
    "    data_temp = pd.DataFrame({\n",
    "    \"sumstat_dir\" : [$[_input[\"nominal\"]:r,]],\n",
    "    \"column_info\" : $[_output[1]:r]\n",
    "    })\n",
    "    column_info_df = pd.DataFrame( pd.Series( {\"ID\": \"molecular_trait_id,chromosome,position,ref,alt\",\n",
    "      \"chromosome\": \"chrom\",\n",
    "      \"position\": \"pos\",\n",
    "      \"ref\": \"ref\",\n",
    "      \"alt\": \"alt\",\n",
    "      \"variant\": \"variant_id\",\n",
    "      \"beta\": \"beta\",\n",
    "      \"se\": \"se\",\n",
    "      \"pvalue\": \"pval\",\n",
    "      \"maf\": \"maf\",\n",
    "      \"molecular_trait_id\": \"gene_ID\"}), columns = [\"TensorQTL\"] )\n",
    "    data_temp.to_csv(\"$[_output[0]]\",index = False,sep = \"\\t\" )\n",
    "    column_info_df.to_csv(\"$[_output[1]]\",index = True,sep = \"\\t\" )\n",
    "\n",
    "bash: expand= \"$[ ]\", stderr = f'{_output[0]}.stderr', stdout = f'{_output[0]}.stdout', container = container, entrypoint = entrypoint\n",
    "        for i in $[_output] ; do \n",
    "        echo \"output_info: $i \"\n",
    "        echo \"output_size:\" `ls -lh $i | cut -f 5  -d  \" \"` \n",
    "        echo \"output_rows:\" `cat $i | wc -l  | cut -f 1 -d \" \"` \n",
    "        echo \"output_headerow:\" `cat $i | grep \"##\" | wc -l ` \n",
    "        echo \"output_column:\" `cat $i | grep -V \"##\" | head -1 | wc -w ` \n",
    "        echo \"output_preview:\" \n",
    "        cat $i  | grep -v \"##\" | head  | cut -f 1,2,3,4,5,6,7,8,9,10 ; done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SoS",
   "language": "sos",
   "name": "sos"
  },
  "language_info": {
   "codemirror_mode": "sos",
   "file_extension": ".sos",
   "mimetype": "text/x-sos",
   "name": "sos",
   "nbconvert_exporter": "sos_notebook.converter.SoS_Exporter",
   "pygments_lexer": "sos"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
