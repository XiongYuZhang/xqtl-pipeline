{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Quantile regression of QTL association testing\n",
    "This notebook implements a workflow for using [quantile regression of QTL](https://pubmed.ncbi.nlm.nih.gov/37333162/) to perform quantile QTL association testing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "## Input\n",
    "\n",
    "- molecular phenotype files: the whole `bed.gz` file containing the table for the molecular phenotype. It should have a companion index file in `tbi` format.\n",
    "\n",
    "    The header of the bed.gz is per the [TensorQTL](https://github.com/broadinstitute/tensorqtl) convention:\n",
    "\n",
    "    >    Phenotypes must be provided in BED format, with a single header line starting with # and the first four columns corresponding to: chr, start, end, phenotype_id, with the remaining columns corresponding to samples (the identifiers must match those in the genotype input). The BED file should specify the center of the cis-window (usually the TSS), with start == end-1.\n",
    "\n",
    "\n",
    "- List of genotypes in PLINK binary format (`bed`/`bim`/`fam`) for each gene, previously processed through our genotype QC pipelines.\n",
    "- Covariate file, a file with #id + samples name as colnames and each row a covariate: fixed and known covariates as well as hidden covariates recovered from factor analysis.\n",
    "- Optionally, a list of traits (genes, regions of molecular features etc) to analyze. In this case, AD gene list and tad list are used, and only analyze the overlapped genes of phenotype data and 76 genes from the AD GWAS list which have AD signal. The tad list is used to perform genomic region analysis and get customized window size.\n",
    "\n",
    "    \n",
    "\n",
    "## Output\n",
    "\n",
    "For each gene, several of summary statistics files are generated, including cis nominal test statistics for each test.\n",
    "\n",
    "The columns of cis nominal association result are as follows:\n",
    "\n",
    "- pheno_id: Molecular trait identifier.(gene)\n",
    "- geno_id: ID of the variant (rsid or chr:position:ref:alt)\n",
    "- chr : Variant chromosome.\n",
    "- pos : Variant chromosomal position (basepairs).\n",
    "- ref : Variant reference allele (A, C, T, or G).\n",
    "- alt : Variant alternate allele.\n",
    "- heterogeneityï¼š heterogeneity index of each snp\n",
    "- is_alt_minor: Whether the minor allele frequency is for the alternate allele\n",
    "- maf: Minor allele frequency\n",
    "- ma_samples: Number of samples carrying the minor allele\n",
    "- ma_count: Total number of minor alleles across individuals\n",
    "- p_qr_cauchy(composite-p value using cauchy combination method): the integrated QR p-value across multiple quantile levels. \n",
    "- p_qr(default composite-p value in QRank package): the integrated QR p-value across multiple quantile levels.    \n",
    "- p_qr_0.1 to p_qr_0.9: quantile-specific QR p-values for the quantile levels 0.1, 0.2, ..., 0.9.   \n",
    "- coef_qr_0.1 to coef_qr_0.9: quantile-specific QR coefficients for the quantile levels 0.1, 0.2, ..., 0.9.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS"
   },
   "source": [
    "# Command interface "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: sos run /home/al4225/project/xqtl-pipeline/code/quantile_qtl/quantile_qtl.ipynb\n",
      "               [workflow_name | -t targets] [options] [workflow_options]\n",
      "  workflow_name:        Single or combined workflows defined in this script\n",
      "  targets:              One or more targets to generate\n",
      "  options:              Single-hyphen sos parameters (see \"sos run -h\" for details)\n",
      "  workflow_options:     Double-hyphen workflow-specific parameters\n",
      "\n",
      "Workflows:\n",
      "  get_analysis_regions\n",
      "  qrqtl\n",
      "\n",
      "Global Workflow Options:\n",
      "  --genoFile VAL (as path, required)\n",
      "                        A list of file paths for genotype data.\n",
      "  --phenoFile  paths\n",
      "\n",
      "                        One or multiple lists of file paths for phenotype data.\n",
      "  --covFile  paths\n",
      "\n",
      "                        Covariate file path\n",
      "  --region-list . (as path)\n",
      "                        Optional: if a region list is provide the analysis will\n",
      "                        be focused on provided region. The LAST column of this\n",
      "                        list will contain the ID of regions to focus on\n",
      "                        Otherwise, all regions with both genotype and phenotype\n",
      "                        files will be analyzed\n",
      "  --region-name  (as list)\n",
      "                        Optional: if a region name is provided the analysis\n",
      "                        would be focused on the union of provides region list\n",
      "                        and region names\n",
      "  --cwd output (as path)\n",
      "  --name VAL (as str, required)\n",
      "                        It is required to input the name of the analysis\n",
      "  --utils-R pipeline/xqtl_utils.R (as path)\n",
      "                        path to utility script. In the future we will\n",
      "                        consolidate this into an R package.\n",
      "  --container ''\n",
      "  --entrypoint  ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
      "\n",
      "  --job-size 5 (as int)\n",
      "                        For cluster jobs, number commands to run per job\n",
      "  --walltime 20h\n",
      "                        Wall clock time expected\n",
      "  --mem 16G\n",
      "                        Memory expected\n",
      "  --numThreads 2 (as int)\n",
      "                        Number of threads\n",
      "  --phenotype-names  [f'{x:bn}' for x in phenoFile]\n",
      "\n",
      "                        Name of phenotypes\n",
      "\n",
      "Sections\n",
      "  get_analysis_regions:\n",
      "  qrqtl_1:\n",
      "    Workflow Options:\n",
      "      --imiss 1 (as int)\n",
      "      --mac 0 (as int)\n",
      "                        Minor allele count cutoff\n",
      "      --maf  mac/(2.0*N)\n",
      "\n",
      "                        Minor allele frequency cutoff. It will overwrite minor\n",
      "                        allele cutoff.\n",
      "  qrqtl_2:\n"
     ]
    }
   ],
   "source": [
    "!sos run /home/al4225/project/xqtl-pipeline/code/quantile_qtl/quantile_qtl.ipynb -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nohup sos run /home/al4225/project/quantile_qtl/rq_pqtl_ad_cis.ipynb qrqtl \\\n",
    "    --name snuc_pseudo_bulk_mic \\\n",
    "    --genoFile /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/plink_by_gene/extended_cis_before_winsorize_plink_files/ROSMAP_NIA_WGS.leftnorm.bcftools_qc.plink_qc.plink_files_list.txt \\\n",
    "    --phenoFile /home/al4225/pseudobulk/output/data_preprocessing/phenotype_data/mic/pheno_list.txt \\\n",
    "    --region-list /home/al4225/project/quantile_qtl/ad_geneid_list.txt \\\n",
    "    --covFile /mnt/vast/hpc/homes/al4225/pseudobulk/output/data_preprocessing/covariate_data/Mic.log2cpm.mic.rosmap_cov.ROSMAP_NIA_WGS.leftnorm.bcftools_qc.plink_qc.snuc_pseudo_bulk.related.plink_qc.extracted.pca.projected.Marchenko_PC.gz \\\n",
    "    --cwd /home/al4225/project/quantile_qtl/output/mic3/ \\\n",
    "    --container /home/al4225/project/quantile_container/quantqtl.sif \\\n",
    "    --mem 200G -J 50 -c /home/al4225/project/quantile_qtl/csg.yml -q csg -s build >./nohup_quantile_mic.out6 &\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "kernel": "SoS",
    "tags": []
   },
   "source": [
    "## Global parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sos"
    }
   },
   "outputs": [],
   "source": [
    "[global]\n",
    "# A list of file paths for genotype data. \n",
    "parameter: genoFile = path\n",
    "# One or multiple lists of file paths for phenotype data.\n",
    "parameter: phenoFile = paths\n",
    "# Covariate file path\n",
    "parameter: covFile = paths\n",
    "# Optional: if a region list is provide the analysis will be focused on provided region. \n",
    "# The LAST column of this list will contain the ID of regions to focus on\n",
    "# Otherwise, all regions with both genotype and phenotype files will be analyzed\n",
    "parameter: region_list = path()\n",
    "# Optional: if a region name is provided \n",
    "# the analysis would be focused on the union of provides region list and region names\n",
    "parameter: region_name = []\n",
    "parameter: cwd = path(\"output\")\n",
    "# It is required to input the name of the analysis\n",
    "parameter: name = str\n",
    "# path to utility script. In the future we will consolidate this into an R package.\n",
    "parameter: utils_R = path(\"pipeline/xqtl_utils.R\")\n",
    "parameter: container = \"\"\n",
    "import re\n",
    "parameter: entrypoint= ('micromamba run -a \"\" -n' + ' ' + re.sub(r'(_apptainer:latest|_docker:latest|\\.sif)$', '', container.split('/')[-1])) if container else \"\"\n",
    "# For cluster jobs, number commands to run per job\n",
    "parameter: job_size = 5\n",
    "# Wall clock time expected\n",
    "parameter: walltime = \"20h\"\n",
    "# Memory expected\n",
    "parameter: mem = \"16G\"\n",
    "# Number of threads\n",
    "parameter: numThreads = 2\n",
    "# Name of phenotypes\n",
    "parameter: phenotype_names = [f'{x:bn}' for x in phenoFile]\n",
    "utils_R = f\"{utils_R:a}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    #chr    start      end               ID  \\\n",
      "0  chr12   389319   389320  ENSG00000073614   \n",
      "1  chr12   752578   752579  ENSG00000060237   \n",
      "2  chr12   990052   990053  ENSG00000002016   \n",
      "3  chr12   990508   990509  ENSG00000082805   \n",
      "4  chr12  1688573  1688574  ENSG00000006831   \n",
      "\n",
      "                                                path  \n",
      "0  /home/al4225/pseudobulk/output/data_preprocess...  \n",
      "1  /home/al4225/pseudobulk/output/data_preprocess...  \n",
      "2  /home/al4225/pseudobulk/output/data_preprocess...  \n",
      "3  /home/al4225/pseudobulk/output/data_preprocess...  \n",
      "4  /home/al4225/pseudobulk/output/data_preprocess...  \n",
      "there are 7762 rows(genes) and 5 cols in pheno list file\n"
     ]
    }
   ],
   "source": [
    "# this aims to show an example of pheno list\n",
    "import pandas as pd\n",
    "pheno = pd.read_csv('/home/al4225/pseudobulk/output/data_preprocessing/phenotype_data/mic/pheno_list.txt', sep = '\\t')\n",
    "print(pheno.head())\n",
    "rows, cols = pheno.shape\n",
    "print(f\"there are {rows} rows(genes) and {cols} cols in pheno list file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   #chr      start        end          gene_id\n",
      "0  chr1  109397917  109397918  ENSG00000134243\n",
      "1  chr1  207496146  207496147  ENSG00000203710\n",
      "2  chr2    9556731    9556732  ENSG00000151694\n",
      "3  chr2   37324832   37324833  ENSG00000115825\n",
      "4  chr2  105744911  105744912  ENSG00000071051\n",
      "there are 76 rows(genes) and 4 cols in ad_id_list file\n"
     ]
    }
   ],
   "source": [
    "# this aims to show an example of resion list: last col: gene_id\n",
    "import pandas as pd\n",
    "ad_id_list = pd.read_csv('/home/al4225/project/quantile_qtl/ad_geneid_list.txt', sep = '\\t')\n",
    "print(ad_id_list.head())\n",
    "rows, cols = ad_id_list.shape\n",
    "print(f\"there are {rows} rows(genes) and {cols} cols in ad_id_list file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               #id                                                dir\n",
      "0  ENSG00000008128  /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/...\n",
      "1  ENSG00000008130  /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/...\n",
      "2  ENSG00000067606  /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/...\n",
      "3  ENSG00000069424  /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/...\n",
      "4  ENSG00000078369  /mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/...\n",
      "there are 26806 rows(genes) and 2 cols in geno list file\n"
     ]
    }
   ],
   "source": [
    "# this aims to show an example of geno list.\n",
    "import pandas as pd\n",
    "geno = pd.read_csv('/mnt/vast/hpc/csg/FunGen_xQTL/ROSMAP/Genotype/plink_by_gene/extended_cis_before_winsorize_plink_files/ROSMAP_NIA_WGS.leftnorm.bcftools_qc.plink_qc.plink_files_list.txt', sep = '\\t')\n",
    "\n",
    "print(geno.head())\n",
    "rows, cols = geno.shape\n",
    "print(f\"there are {rows} rows(genes) and {cols} cols in geno list file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile regression to call xqlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sos"
    }
   },
   "outputs": [],
   "source": [
    "[get_analysis_regions: shared = \"regional_data\"]\n",
    "# input is genoFile, phenoFile, covFile and optionally region_list. If region_list presents then we only analyze what's contained in the list.\n",
    "# regional_data should be a dictionary with:\n",
    "# 1. a list of tuples: {data: [(gene_1.genotype, condition_1, cov_1), (gene_2.genotype, condition_1, cov_1, condition_2, cov_2), ...]} each element may not be of the same length\n",
    "# 2. a list of region meta_info: {meta_info: ( \"chr:start-end\",gene_1,\"cond_1\"), (\"chr:start-end\",gene_2, \"cond_1','cond_2\"), ...]}\n",
    "import pandas as pd\n",
    "import os\n",
    "genoFile = pd.read_csv(genoFile, sep = \"\\t\", header=0)\n",
    "\n",
    "if len(phenoFile) != len(covFile):\n",
    "    raise ValueError(\"Number of input phenotypes files must match that of covariates files\")\n",
    "if len(phenoFile) != len(phenotype_names):\n",
    "    raise ValueError(\"Number of input phenotypes files must match the number of phenotype names\")\n",
    "## pos and covar are condition specific, this way when there is no phenotype file, there is na in the corresponding column.\n",
    "phenoFile = [pd.read_csv(x, sep = \"\\t\", header=0).assign(pos = lambda y:y['#chr']+':'+y['start'].astype(\"str\")+'-'+\n",
    "                                              y['end'].astype(\"str\")).assign(cov_path = z, cond = a ).drop(columns = [\"#chr\",\"start\",\"end\"]).rename(columns = {\"ID\":\"#id\"})   \n",
    "             for x,z,a in zip(phenoFile,covFile,phenotype_names)]\n",
    "for i in range(len(phenoFile)):\n",
    "    genoFile = genoFile.merge(phenoFile[i], on='#id', how='left', suffixes = (f'{i}_x', f'{i}_y'))\n",
    "\n",
    "# remove id that has no phenotype.\n",
    "\n",
    "genoFile = genoFile[~genoFile.drop(columns=['#id',\"dir\"]).isna().all(axis=1)]    \n",
    "\n",
    "if len(genoFile.index) == 0:\n",
    "    raise ValueError(\"No region overlap between genotype #id and any of the phenotypes ID\")\n",
    "\n",
    "# Get position for meta_data\n",
    "pos_col = [col for col in genoFile.columns if col.startswith('pos')]\n",
    "genoFile.index = pd.Series(genoFile[pos_col].values.flatten()).dropna()\n",
    "# Get the conditions strings for each ID\n",
    "cond_col = [col for col in genoFile.columns if col.startswith('cond')]\n",
    "genoFile[\"phenotype_names\"] = [\"','\".join(pd.Series((x)).dropna()) for x in genoFile[cond_col].to_dict(\"split\")[\"data\"]]\n",
    "# Clean up\n",
    "genoFile = genoFile.drop(columns = cond_col).drop(columns = pos_col)\n",
    "\n",
    "\n",
    "region_ids = []\n",
    "\n",
    "# If region_list is provided, read the file and extract IDs\n",
    "if region_list.is_file():\n",
    "    region_list_df = pd.read_csv(region_list, sep = \"\\t\", header=None, comment = \"#\")\n",
    "    region_ids = region_list_df.iloc[:, -1].unique()  # Extracting the last column for IDs\n",
    "\n",
    "# If region_name is provided, include those IDs as well\n",
    "# --region-name A B C will result in a list of [\"A\", \"B\", \"C\"] here\n",
    "if len(region_name) > 0:\n",
    "    region_ids = list(set(region_ids).union(set(region_name)))\n",
    "\n",
    "# If either region_list or region_name is provided, filter the genoFile\n",
    "if len(region_ids) > 0:\n",
    "    genoFile = genoFile[genoFile['#id'].isin(region_ids)]\n",
    "\n",
    "file_inv = genoFile.drop(columns = [\"#id\", \"phenotype_names\"]).to_dict(\"split\")\n",
    "file_inv['data'] = [[value for value in sublist if not pd.isna(value)] for sublist in file_inv['data']] \n",
    "\n",
    "\n",
    "## There will alwayse be genotype file due to left join,\n",
    "## There will alwayse be covar file as len(covFile) must == len(PhenoFile), and covar column is the same string accross all rows\n",
    "## So only if there is no bed.gz there will be problem.\n",
    "regional_data = {\"data\":file_inv[\"data\"],\"meta_info\": genoFile[[\"#id\",\"phenotype_names\"]].reset_index().to_dict(\"split\")['data'] }\n",
    "\n",
    "# Recreate file_inv based on the filtered genoFile\n",
    "file_inv = genoFile.drop(columns=[\"#id\", \"phenotype_names\"]).to_dict(\"split\")\n",
    "file_inv['data'] = [[value for value in sublist if not pd.isna(value)] for sublist in file_inv['data']] \n",
    "\n",
    "# Recreate the regional_data based on the filtered data\n",
    "regional_data = {\"data\": file_inv[\"data\"],\n",
    "                 \"meta_info\": genoFile[[\"#id\", \"phenotype_names\"]].reset_index().to_dict(\"split\")['data']}\n",
    "print(\"regional_data first 2 rows:\")\n",
    "for row in regional_data['data'][:2]:\n",
    "    print(row)\n",
    "for row in regional_data['meta_info'][:2]:\n",
    "    print(row)\n",
    "num_of_rows = len(regional_data['meta_info'])\n",
    "print(f\"meta_info has {num_of_rows} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sos"
    }
   },
   "outputs": [],
   "source": [
    "[qrqtl_1]\n",
    "parameter: imiss = 1\n",
    "# Minor allele count cutoff\n",
    "parameter: mac = 0\n",
    "import pandas as pd\n",
    "N = len(pd.read_csv(covFile, sep = \"\\t\",nrows = 1).columns) - 1 # Use the header of covariate file for it being the intersect of geno/pheno/cov.\n",
    "# Minor allele frequency cutoff. It will overwrite minor allele cutoff.\n",
    "parameter: maf = mac/(2.0*N)\n",
    "\n",
    "depends: sos_variable(\"regional_data\")\n",
    "\n",
    "def group_by_region(lst, data):\n",
    "    vector = [len(x) for x in data]\n",
    "    return [lst[sum(vector[:i]):sum(vector[:i+1])] for i in range(len(vector))]\n",
    "\n",
    "meta_info = regional_data['meta_info']\n",
    "input: regional_data[\"data\"], group_by = lambda x: group_by_region(x, regional_data[\"data\"]), group_with = \"meta_info\"\n",
    "output: qr_nominal_result = f'{cwd:a}/{step_name[:-2]}/{name}.{_meta_info[1]}.qr_nominal_result.rds'\n",
    "task: trunk_workers = 1, trunk_size = job_size, walltime = walltime, mem = mem, cores = numThreads, tags = f'{step_name}_{_output[0]:bn}'\n",
    "R: expand = '${ }', stdout = f\"{_output:n}.stdout\", stderr = f\"{_output:n}.stderr\", container = container, entrypoint = entrypoint, input = utils_R\n",
    "library(\"tidyverse\")\n",
    "library(QRank)\n",
    "library(quantreg)\n",
    "\n",
    "    # Load regional association data\n",
    "    fdat = load_regional_quantile_data(genotype = ${_input[0]:anr},\n",
    "                                          phenotype = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[1::2]])}),\n",
    "                                          covariate = c(${\",\".join(['\"%s\"' % x.absolute() for x in _input[2::2]])}),\n",
    "                                          region = \"${_meta_info[0]}\",\n",
    "                                          conditions = c('${_meta_info[2]}'),\n",
    "                                          maf_cutoff = ${maf},\n",
    "                                          mac_cutoff = ${mac},\n",
    "                                          imiss_cutoff = ${imiss},\n",
    "                                          y_as_matrix = FALSE)\n",
    "    # Print the head of Y, X_data, and covar\n",
    "    print(\"Head of Y:\")\n",
    "    print(dim(fdat$Y[[1]]))\n",
    "    print(head(fdat$Y[[1]]))\n",
    "\n",
    "    print(\"Head of X_data:\")\n",
    "    print(dim(fdat$X_data[[1]]))\n",
    "\n",
    "    print(\"Head of covar:\")\n",
    "    print(dim(fdat$covar[[1]]))\n",
    "    print(head(fdat$covar[[1]]))\n",
    "    \n",
    "    # QRank test\n",
    "    ## Cauchy combination\n",
    "    cauchy.meta <- function(pvals) {\n",
    "    # Check input\n",
    "    pvals = pvals[!is.na(pvals)]\n",
    "    if (length(pvals) == 0) {\n",
    "        return(NA)\n",
    "    }\n",
    "    # pvals[pvals == 0] = 2.2E-308\n",
    "    # Convert to Cauchy\n",
    "    cauchy = 1 / (pvals * pi)\n",
    "    cauchy[pvals >= 1e-15] = tanpi(0.5 - pvals[pvals >= 1e-15])\n",
    "    stats = mean(cauchy)\n",
    "    p = pcauchy(q = stats, lower.tail = F)\n",
    "    return(p)\n",
    "    }\n",
    "    \n",
    "\n",
    "start_time <- proc.time()\n",
    "# Qrank for p \n",
    "#fitted = list()\n",
    "fitted <- vector(\"list\", length(fdat$Y))\n",
    "cat(\"length(fdat$Y)\", length(fdat$Y), \"\\n\")\n",
    "for (r in 1:length(fdat$Y)) {\n",
    "    st = proc.time()\n",
    "    qntl <- (1:9) / 10\n",
    "    genotype_df = fdat$X_data[[r]]\n",
    "    phenotype_df = fdat$Y[[r]]\n",
    "    colnames(phenotype_df) = c('${_meta_info[1]}')\n",
    "    covariates_df = fdat$covar[[r]]\n",
    "\n",
    "    df.p <- data.frame()\n",
    "    additional_info_df <- data.frame(pheno_id = character(), geno_id = character(), is_alt_minor = logical(), maf = numeric(), ma_samples = integer(), ma_count = integer())\n",
    "\n",
    "    for (i in 1:ncol(genotype_df)) {\n",
    "        geno_data <- genotype_df[, i]\n",
    "        alt_allele_freq <- mean(geno_data) / 2\n",
    "        if (alt_allele_freq > 0.5) {\n",
    "            MAF <- 1 - alt_allele_freq\n",
    "            is_minor <- FALSE\n",
    "        } else {\n",
    "            MAF <- alt_allele_freq\n",
    "            is_minor <- TRUE\n",
    "        }\n",
    "        af <- MAF\n",
    "        if (is_minor) {\n",
    "            ma_samples <- sum(geno_data > 0.5)\n",
    "            ma_count <- round(sum(geno_data))\n",
    "        } else {\n",
    "            ma_samples <- sum(geno_data < 1.5)\n",
    "            ma_count <- round(2 * length(geno_data) - sum(geno_data))\n",
    "        }\n",
    "        ma_count <- as.integer(ma_count)\n",
    "        additional_info_row <- data.frame(pheno_id = colnames(phenotype_df), geno_id = colnames(genotype_df)[i], is_alt_minor = is_minor, maf = af, ma_samples = ma_samples, ma_count = ma_count)\n",
    "        additional_info_df <- rbind(additional_info_df, additional_info_row)\n",
    "\n",
    "        p.qr <- QRank(gene = as.matrix(phenotype_df), \n",
    "                          cov = as.matrix(covariates_df), \n",
    "                          snp = geno_data, \n",
    "                          tau = qntl)\n",
    "        heterogeneity_result <- heter.QRank(p.qr)\n",
    "        heterogeneity_metric <- heterogeneity_result$`heter.index`\n",
    "        col_names <- c('p_qr_cauchy', 'p_qr', paste0('p_qr_', qntl), 'heterogeneity')\n",
    "        df.row <- data.frame(pheno_id = colnames(phenotype_df), geno_id = colnames(genotype_df)[i], 'p_qr_cauchy' = cauchy.meta(as.numeric(p.qr$quantile.specific.pvalue)),'p_qr' = p.qr$composite.pvalue ,t(p.qr$quantile.specific.pvalue), heterogeneity = heterogeneity_metric)\n",
    "        names(df.row) <- c(\"pheno_id\", \"geno_id\", col_names)\n",
    "        df.p <- rbind(df.p, df.row)\n",
    "    }\n",
    "    cis_nominal_p <- merge(df.p, additional_info_df)\n",
    "    cat(\"qrank loaded \", dim(cis_nominal_p), \"\\n\")\n",
    "    print(head(cis_nominal_p))\n",
    "\n",
    "start_time2 <- proc.time()\n",
    "# quantile regression--get beta\n",
    "# coef result of tau from 0.1 to 0.9\n",
    "pheno.mat = as.matrix(phenotype_df)\n",
    "geno.mat = as.matrix(genotype_df)\n",
    "cova.mat = as.matrix(covariates_df)\n",
    "result_table_br <- data.frame(pheno_id = character(),\n",
    "                           geno_id = character(),\n",
    "                           tau = numeric(),\n",
    "                           predictor_coef = numeric(),\n",
    "                           stringsAsFactors = FALSE)\n",
    "\n",
    "for (tau in seq(0.1, 0.9, by = 0.1)) {\n",
    "     for (n in 1:ncol(geno.mat)){\n",
    "      \n",
    "      response <- pheno.mat\n",
    "      predictor <- geno.mat[, n]\n",
    "      if (!is.null(cova.mat)) {\n",
    "        X <- cbind(1, predictor, cova.mat)\n",
    "      } else {\n",
    "        X <- cbind(1, predictor)\n",
    "      }\n",
    "      \n",
    "      pheno_id <- colnames(pheno.mat)\n",
    "      geno_id <- colnames(geno.mat)[n]\n",
    "\n",
    "      # Using rq.fit.br\n",
    "      mod_br <- rq.fit.br(X, response, tau = tau)\n",
    "      predictor_coef_br <- mod_br$coefficients[2] #get the coefficient of variant\n",
    "      \n",
    "      row_br <- data.frame(pheno_id = pheno_id, geno_id = geno_id, tau = tau, predictor_coef = predictor_coef_br, stringsAsFactors = FALSE)\n",
    "      result_table_br <- rbind(result_table_br, row_br)\n",
    "    }\n",
    "}\n",
    "\n",
    "result_table_wide = result_table_br %>% pivot_wider(names_from = tau, values_from = predictor_coef)\n",
    "colnames(result_table_wide)[3:ncol(result_table_wide)] <- paste0(\"coef_qr_\", colnames(result_table_wide)[3:ncol(result_table_wide)])\n",
    " cat(\"rq.fit.br result loaded \", dim(result_table_wide), \"\\n\")\n",
    "print(head(result_table_wide))\n",
    "end_time2 <- proc.time()\n",
    "cat(\"rq loaded and time is\", end_time2 - start_time2, \"seconds\\n\")\n",
    "\n",
    "# combined p(composite-p from default QRank and cauchy method) and coef table\n",
    "## QR summary statistics\n",
    "## row: variant\n",
    "## column: p-value, coefficient and other parameters\n",
    "qr_nominal_result = merge(cis_nominal_p, result_table_wide, by = c(\"pheno_id\", \"geno_id\")) %>%\n",
    "  separate(geno_id, into = c(\"chr\", \"pos\", \"ref\", \"alt\"), sep = \"[:_]\", remove = FALSE) %>%\n",
    "  mutate(chr = as.numeric(gsub(\"chr\", \"\", chr)), pos = as.numeric(pos))\n",
    "  cat(\"combined p and beta result loaded: \",dim(qr_nominal_result) , \"\\n\")\n",
    "column_names <- colnames(qr_nominal_result)\n",
    "\n",
    "#change order\n",
    "new_order <- c(column_names[3:6], column_names[1:2], column_names[7:17], column_names[23:length(column_names)])\n",
    "qr_nominal_result <- qr_nominal_result[new_order]\n",
    "print(head(qr_nominal_result))\n",
    "\n",
    "fitted[[r]]$analysis_time <- proc.time() - st\n",
    "fitted[[r]]$df.p = df.p\n",
    "fitted[[r]]$additional_info_df = additional_info_df\n",
    "fitted[[r]]$p.qr = p.qr\n",
    "fitted[[r]]$cis_nominal_p = cis_nominal_p\n",
    "fitted[[r]]$result_table_wide = result_table_wide\n",
    "fitted[[r]]$qr_nominal_result = qr_nominal_result\n",
    "\n",
    "}\n",
    "names(fitted) <- names(fdat$Y)\n",
    "saveRDS(fitted, ${_output:ar})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sos"
    }
   },
   "outputs": [],
   "source": [
    "[qrqtl_2]\n",
    "input: group_by = \"all\"\n",
    "output: f'{cwd}/{name}.quantqtl_output2.txt'\n",
    "python: expand= \"$[ ]\", stderr = f'{_output:n}.stderr', stdout = f'{_output:n}.stdout'\n",
    "    import pandas as pd\n",
    "    pd.DataFrame({\"output\" : [$[_input:ar,]]}).to_csv(\"$[_output]\",index = False ,header = False, sep = \"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (my_kernel)",
   "language": "python",
   "name": "my_python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "sos": {
   "kernels": [
    [
     "Bash",
     "Bash",
     "#E6EEFF",
     ""
    ],
    [
     "SoS",
     "sos",
     "",
     "",
     "sos"
    ]
   ],
   "version": "0.24.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
